{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0739ba1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:32:34.626135Z",
     "start_time": "2024-07-29T16:32:34.300083Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "semanticforce_file = open('kyiv_digital_sentiment_annotation - Annotator X.tsv')\n",
    "data = pd.read_csv(semanticforce_file,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "437fde84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:32:35.776783Z",
     "start_time": "2024-07-29T16:32:35.746236Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('emotions_sentiment_youscan - Annotator 1 - Veronika.tsv','r') as file3:\n",
    "    data3=list(file3)\n",
    "    data3=[e.replace('\\n','').split('\\t')[0:2] for e in data3[1:652]]\n",
    "data2 = pd.DataFrame(data3, columns=['content', 'label'])\n",
    "df = pd.concat([data, data2], ignore_index=True)\n",
    "label_mapping = {'Neutral': 0, 'Negative': 1, 'Positive': 2,'Very Positive':2,'Very Negative':1, 'Mixed':1}\n",
    "df['label'] =df['label'].map(label_mapping)\n",
    "df = df.dropna()\n",
    "df['label'] =df['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43fb6159",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:32:44.231064Z",
     "start_time": "2024-07-29T16:32:43.110163Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, load_metric\n",
    "from sklearn.metrics import roc_auc_score, f1_score, matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcfa12bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:33:14.923228Z",
     "start_time": "2024-07-29T16:33:14.884098Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.1, stratify=df['label'], random_state=42)\n",
    "\n",
    "# Convert DataFrame to Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90896c93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:33:40.353444Z",
     "start_time": "2024-07-29T16:33:40.346459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['content', 'label', '__index_level_0__'],\n",
       "    num_rows: 122\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14d4fcad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:41:39.226963Z",
     "start_time": "2024-07-29T16:41:39.218212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 122)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds),len(val_dataset['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f521d79b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T17:28:37.033874Z",
     "start_time": "2024-07-29T17:28:29.401757Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|███| 1.41k/1.41k [00:00<00:00, 2.15MB/s]\n",
      "Downloading data: 100%|█████| 21.5M/21.5M [00:01<00:00, 13.7MB/s]\n",
      "Downloading data: 100%|█████| 8.35M/8.35M [00:00<00:00, 9.73MB/s]\n",
      "Generating train split: 100%|█| 128549/128549 [00:00<00:00, 14305\n",
      "Generating test split: 100%|█| 52294/52294 [00:00<00:00, 2380655.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d98e8faa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T17:28:43.784295Z",
     "start_time": "2024-07-29T17:28:43.777161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d812ba4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T17:29:10.637021Z",
     "start_time": "2024-07-29T17:29:10.472495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128549"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['train']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3da6fa45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:03:33.083377Z",
     "start_time": "2024-07-29T18:03:32.834535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"чому редагування, зроблені за моїм ім'ям жорстких мета був повернений вони були не вандалізм щойно закрився на якомусь газі після того як я голосував на нових ляльках fac і будьласка не вилучіть шаблон зі сторінки промови з тих пір, як миттєвий відставку зараз\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "818a9a38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:04:08.258490Z",
     "start_time": "2024-07-29T18:04:08.146025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52294"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['test']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91cdb24c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:04:14.958562Z",
     "start_time": "2024-07-29T18:04:14.871381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Дякую за розуміння, я думаю, дуже високо про вас і не повернеться без обговорення',\n",
       " 'Боже мій, це місце жахливе.',\n",
       " 'хтось завжди буде намагатися додати релігію дійсно Ви маєте на увазі те, як люди незмінно додавали релігію до samuel backetbox і чому ви турбуєтеся, щоб згадати довгосмертних повністю не існує вплив ви просто ви робите висмоктування лайно на льоту для порівняння єдине явне визнання в всій статті амосів, що він особисто є еврей в категорії',\n",
       " \"каже, що це тип інституції потрібний в цьому випадку, тому що є три рівні сонячних університетських центрів та докторського грантування університетів штату Університети, це необхідно в цьому випадку, щоб прояснити, що ub є сонячним центром він каже, що навіть в університеті Бінгемтоні в університеті штату Нью-Йорк і кам'яний тюрк, що намагається сказати не тому, що я повністю правий в цьому випадку\",\n",
       " 'Перш ніж додавати новий продукт до списку, переконайтеся, що його значення додається перед додаванням нового продукту до списку, переконайтеся, що у ньому є запис wikipedia, який вже доводить свою актуальність, а також надає читачеві можливість прочитати більше про нього у іншому випадку, що його може бути викликано вилученням статті з перегляду історії модифікації статей.',\n",
       " 'цей інший від',\n",
       " 'причина заборони вкидання цієї статті потребує розділу про те, чому кидання на даний момент заборонено вентилятору, який не вміє грати, це виглядає досить довільним.',\n",
       " 'заблоковано від редагування Вікіпедії',\n",
       " 'Араби займаються геноцидом в іраку, але жоден протест в європе не може також горіти в пеклі.',\n",
       " 'Зупиніться, будь ласка, якщо ви продовжите вандализувати wikipedia, як ви зробили з гомосексуалізмом, ви будете заблоковані від редагування']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test']['text'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b66ed05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:29:50.538057Z",
     "start_time": "2024-07-29T18:29:50.372625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(29564, 312, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 312)\n",
       "      (token_type_embeddings): Embedding(2, 312)\n",
       "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-2): 3 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=312, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained('./fine_tuned_model2')\n",
    "tokenizer = AutoTokenizer.from_pretrained('./fine_tuned_model2')\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9bbdc51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:30:12.150101Z",
     "start_time": "2024-07-29T18:30:12.084457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 0\n"
     ]
    }
   ],
   "source": [
    "text = \"Your input text here\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "print(f'Predicted class: {predicted_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c30d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    " #{'Neutral': 0, 'Negative': 1, 'Positive': 2,'Very Positive':2,'Very Negative':1, 'Mixed':1}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nika",
   "language": "python",
   "name": "nika"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
