{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and data read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://platform.openai.com/docs/api-reference/authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'sk-proj-7yyg4KC696T7WK6CmLeWT3BlbkFJfjiC6bs5r8R7yoGLCIUP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('./data_provided/final_dataset/final_17042025.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12224 entries, 0 to 12223\n",
      "Data columns (total 18 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   response_id           12224 non-null  int64 \n",
      " 1   document_id           12224 non-null  int64 \n",
      " 2   user_id               12224 non-null  int64 \n",
      " 3   annotator_sentiment   12224 non-null  object\n",
      " 4   is_ck_annotation      12224 non-null  int64 \n",
      " 5   response_timestamp    12224 non-null  object\n",
      " 6   document_content      12224 non-null  object\n",
      " 7   annotation_date       12224 non-null  object\n",
      " 8   username              12224 non-null  object\n",
      " 9   unique_document_id    12224 non-null  object\n",
      " 10  language_wc           12224 non-null  object\n",
      " 11  document_length       12224 non-null  int64 \n",
      " 12  gpt_labels_v1         12224 non-null  object\n",
      " 13  language_gpt          12224 non-null  object\n",
      " 14  language_manual       12224 non-null  object\n",
      " 15  language              12224 non-null  object\n",
      " 16  stratification_label  12224 non-null  object\n",
      " 17  df_set                12224 non-null  object\n",
      "dtypes: int64(5), object(13)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ua', 'ru', 'mixed'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratification label balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core idea is to reduce the imbalance between classes in the dataset by generating new samples by Chat GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stratification_label\n",
       "neutral_ua        3291\n",
       "negative_ua       2433\n",
       "positive_ua       1859\n",
       "negative_ru       1799\n",
       "neutral_ru        1208\n",
       "mixed_ua           442\n",
       "positive_ru        441\n",
       "negative_mixed     309\n",
       "neutral_mixed      203\n",
       "mixed_ru           120\n",
       "positive_mixed      73\n",
       "mixed_mixed         46\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stratification_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_stratification = df.stratification_label.value_counts().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(3291)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_augment = (df.stratification_label.value_counts() - max_stratification).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_augment['count'] = classes_to_augment['count'].apply(abs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stratification_label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral_ua</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative_ua</td>\n",
       "      <td>858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive_ua</td>\n",
       "      <td>1432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative_ru</td>\n",
       "      <td>1492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral_ru</td>\n",
       "      <td>2083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mixed_ua</td>\n",
       "      <td>2849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive_ru</td>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>negative_mixed</td>\n",
       "      <td>2982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neutral_mixed</td>\n",
       "      <td>3088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mixed_ru</td>\n",
       "      <td>3171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>positive_mixed</td>\n",
       "      <td>3218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mixed_mixed</td>\n",
       "      <td>3245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stratification_label  count\n",
       "0            neutral_ua      0\n",
       "1           negative_ua    858\n",
       "2           positive_ua   1432\n",
       "3           negative_ru   1492\n",
       "4            neutral_ru   2083\n",
       "5              mixed_ua   2849\n",
       "6           positive_ru   2850\n",
       "7        negative_mixed   2982\n",
       "8         neutral_mixed   3088\n",
       "9              mixed_ru   3171\n",
       "10       positive_mixed   3218\n",
       "11          mixed_mixed   3245"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_to_augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(27268)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_to_augment['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for text in df.loc[(df.stratification_label == 'mixed_mixed'), 'document_content']:\n",
    "#     pprint.pprint(text, width=250)\n",
    "#     print('----------------------------')\n",
    "#     print('----------------------------')\n",
    "#     print('----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(comment, system_prompt):\n",
    "    \"\"\"\n",
    "    Sends a request to OpenAI's GPT model to analyze sentiment.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": comment}\n",
    "        ]\n",
    "    )   \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_inputs = {\n",
    "    'negative_ua': [858, 'include only Ukrainian words', 'negative sentiment'],\n",
    "    'positive_ua': [1432, 'include only Ukrainian words', 'positive sentiment'],\n",
    "    'negative_ru': [1492, 'include only Russian words', 'negative sentiment'],\n",
    "    'neutral_ru': [2083, 'include only Russian words', 'neutral sentiment'],\n",
    "    'mixed_ua': [2849, 'include only Ukrainian words', 'mixed sentiment (express positive and negative emotions in different part of the text output'],\n",
    "    'positive_ru': [2850, 'include only Russian words', 'positive sentiment'],\n",
    "    'negative_mixed': [2982, 'include Ukrainian words as well as Russian (e.g.: \"Доброго вечора, как делишки?\")', 'negative sentiment'],\n",
    "    'neutral_mixed': [3088, 'include Ukrainian words as well as Russian (e.g.: \"Доброго вечора, как делишки?\")', 'neutral sentiment'],\n",
    "    'mixed_ru': [3171, 'include only Russian words', 'mixed sentiment (express positive and negative emotions in different part of the text output'],\n",
    "    'positive_mixed': [3218, 'include Ukrainian words as well as Russian (e.g.: \"Доброго вечора, как делишки?\")', 'positive sentiment'],\n",
    "    'mixed_mixed': [3245, 'include Ukrainian words as well as Russian (e.g.: \"Доброго вечора, как делишки?\")', 'mixed sentiment (express positive and negative emotions in different part of the text output)'],\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_outputs = {\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 858/858 [00:00<00:00, 2384.80it/s]\n",
      "100%|██████████| 1432/1432 [00:00<00:00, 2654.47it/s]\n",
      "100%|██████████| 1492/1492 [00:00<00:00, 2587.65it/s]\n",
      "100%|██████████| 2083/2083 [00:00<00:00, 2771.68it/s]\n",
      "100%|██████████| 2849/2849 [00:00<00:00, 2973.30it/s]\n",
      "100%|██████████| 2850/2850 [00:01<00:00, 2643.97it/s]\n",
      "100%|██████████| 2982/2982 [00:00<00:00, 3034.13it/s]\n",
      "100%|██████████| 3088/3088 [00:00<00:00, 3119.38it/s]\n",
      "100%|██████████| 3171/3171 [00:01<00:00, 3156.01it/s]\n",
      "100%|██████████| 3218/3218 [00:01<00:00, 3150.78it/s]\n",
      "100%|██████████| 3245/3245 [00:01<00:00, 2819.02it/s]\n",
      "100%|██████████| 11/11 [00:09<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "for strat_label, inputs in tqdm(prompt_inputs.items()):\n",
    "\n",
    "    prompt_outputs[strat_label] = []\n",
    "    \n",
    "    for _ in tqdm(range(inputs[0])):\n",
    "        language = inputs[1]\n",
    "        sentiment = inputs[2]\n",
    "        text = df.loc[(df.stratification_label == strat_label), 'document_content'].sample(1).values[0]\n",
    "        \n",
    "\n",
    "\n",
    "        system_prompt_overall = f'''\n",
    "\n",
    "                You are a sentiment analysis expert. You need to help to create a dataset of texts needed for training an ML model. Your help is to write a text which will be included to the dataset. This is important that the text must {language}. The sentiment of the text should express {sentiment}.\n",
    "                The example of such a text is provided below.\n",
    "\n",
    "                Write the text similar to the provided example. You can do just a rewording. However, remember, that the resulted text must {language}. \n",
    "                \n",
    "                Also, uou must write only the text without any additional comments from yourself. \n",
    "\n",
    "            '''\n",
    "        \n",
    "        comment = f'''\n",
    "\n",
    "        The text example is below: \n",
    "        \"\"\"\n",
    "        {text}\n",
    "        \"\"\"\n",
    "\n",
    "        '''\n",
    "\n",
    "        prompt_outputs[strat_label].append(analyze_sentiment(comment, system_prompt=system_prompt_overall))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_prompt_outputs(prompt_outputs, filename='prompt_outputs.pkl'):\n",
    "    \"\"\"\n",
    "    Save the prompt_outputs dictionary to a pickle file.\n",
    "    \n",
    "    Args:\n",
    "        prompt_outputs (dict): The dictionary containing the outputs to save\n",
    "        filename (str): Name of the pickle file to save to (default: 'prompt_outputs.pkl')\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if the save was successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(prompt_outputs, file)\n",
    "        print(f\"Successfully saved prompt_outputs to {filename}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving prompt_outputs: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_prompt_outputs(prompt_outputs, filename='prompt_outputs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_augmented = pd.DataFrame({'stratification_label':[], \n",
    "             'document_content': []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strat_label, texts in tqdm(prompt_outputs.items()):\n",
    "    temp_df = pd.DataFrame({'stratification_label':[strat_label for i in range(len(texts))], \n",
    "             'document_content': texts})\n",
    "\n",
    "    df_augmented = pd.concat([df_augmented, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_augmented.to_parquet('augmentations.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diploma_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
