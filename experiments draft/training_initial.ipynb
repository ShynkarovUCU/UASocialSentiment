{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8e2ebc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T14:19:37.187485Z",
     "start_time": "2024-08-23T14:19:36.409504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вітаю, світе!\n"
     ]
    }
   ],
   "source": [
    "from translate import Translator\n",
    "translator = Translator(to_lang=\"uk\")\n",
    "translation = translator.translate(\"Hello, world!\")\n",
    "print(translation)  # Outputs: 'Hola, mundo!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dd4013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9b80a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T14:19:45.176502Z",
     "start_time": "2024-08-23T14:19:44.402515Z"
    }
   },
   "outputs": [],
   "source": [
    "semanticforce_file = open('kyiv_digital_sentiment_annotation - Annotator X.tsv')\n",
    "data = pd.read_csv(semanticforce_file,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef0e3a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T14:19:45.693932Z",
     "start_time": "2024-08-23T14:19:45.664561Z"
    }
   },
   "outputs": [],
   "source": [
    "data4 = pd.read_csv('telegram_train.csv')\n",
    "data5 = pd.read_csv('telegram_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97781be8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T14:19:46.837283Z",
     "start_time": "2024-08-23T14:19:46.813357Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('emotions_sentiment_youscan - Annotator 1 - Veronika.tsv','r') as file3:\n",
    "    data3=list(file3)\n",
    "    data3=[e.replace('\\n','').split('\\t')[0:2] for e in data3[1:652]]\n",
    "data2 = pd.DataFrame(data3, columns=['content', 'label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75d994d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T14:19:50.391652Z",
     "start_time": "2024-08-23T14:19:48.212619Z"
    }
   },
   "outputs": [],
   "source": [
    "data6 = pd.read_csv('./data/truw.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68dc9329",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T14:19:50.395540Z",
     "start_time": "2024-08-23T14:19:50.393193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276309\n"
     ]
    }
   ],
   "source": [
    "print(len(data6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "180af52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channel_name\n",
       "rian_ru              79663\n",
       "ROSSIYA_SEGODNIA     69238\n",
       "uniannet             67727\n",
       "radiosvoboda         33220\n",
       "UkrPravdaMainNews    22860\n",
       "ZE_kartel             3601\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data6['channel_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e80fada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channel_attitude\n",
       "pro-ru    152502\n",
       "pro-ua    123807\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data6['channel_attitude'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9671778b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gpt_sentiment\n",
       "negative    146808\n",
       "neutral      92331\n",
       "positive     37170\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data6['gpt_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f12f3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>message_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>text</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>channel_attitude</th>\n",
       "      <th>gpt_geopolitical_attitude_standardized</th>\n",
       "      <th>gpt_sentiment</th>\n",
       "      <th>pymorphy_sentiment</th>\n",
       "      <th>gpt_hate_or_discrimination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-01 02:30:20+00:00</td>\n",
       "      <td>Группа бывших американских дипломатов и сотруд...</td>\n",
       "      <td>rian_ru</td>\n",
       "      <td>pro-ru</td>\n",
       "      <td>pro-ukrainian</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-02 22:08:02+00:00</td>\n",
       "      <td>Байден поговорил с Зеленским. Главные тезисы: ...</td>\n",
       "      <td>rian_ru</td>\n",
       "      <td>pro-ru</td>\n",
       "      <td>pro-ukrainian</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-02 22:30:58+00:00</td>\n",
       "      <td>Зеленский сообщил, что обсудил с Байденом дейс...</td>\n",
       "      <td>rian_ru</td>\n",
       "      <td>pro-ru</td>\n",
       "      <td>pro-ukrainian</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-01-03 17:26:38+00:00</td>\n",
       "      <td>В Вашингтоне сильнейшая метель. Байдену, котор...</td>\n",
       "      <td>rian_ru</td>\n",
       "      <td>pro-ru</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-01-03 22:29:35+00:00</td>\n",
       "      <td>Захарова назвала отъезд Цимбалюка из России си...</td>\n",
       "      <td>rian_ru</td>\n",
       "      <td>pro-ru</td>\n",
       "      <td>pro-ukrainian</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  message_id                       Date  \\\n",
       "0           0           0  2022-01-01 02:30:20+00:00   \n",
       "1           1           1  2022-01-02 22:08:02+00:00   \n",
       "2           2           2  2022-01-02 22:30:58+00:00   \n",
       "3           3           3  2022-01-03 17:26:38+00:00   \n",
       "4           4           4  2022-01-03 22:29:35+00:00   \n",
       "\n",
       "                                                text channel_name  \\\n",
       "0  Группа бывших американских дипломатов и сотруд...      rian_ru   \n",
       "1  Байден поговорил с Зеленским. Главные тезисы: ...      rian_ru   \n",
       "2  Зеленский сообщил, что обсудил с Байденом дейс...      rian_ru   \n",
       "3  В Вашингтоне сильнейшая метель. Байдену, котор...      rian_ru   \n",
       "4  Захарова назвала отъезд Цимбалюка из России си...      rian_ru   \n",
       "\n",
       "  channel_attitude gpt_geopolitical_attitude_standardized gpt_sentiment  \\\n",
       "0           pro-ru                          pro-ukrainian       neutral   \n",
       "1           pro-ru                          pro-ukrainian      negative   \n",
       "2           pro-ru                          pro-ukrainian      negative   \n",
       "3           pro-ru                         not applicable       neutral   \n",
       "4           pro-ru                          pro-ukrainian      negative   \n",
       "\n",
       "  pymorphy_sentiment gpt_hate_or_discrimination  \n",
       "0           negative                         no  \n",
       "1           negative                         no  \n",
       "2           negative                         no  \n",
       "3           negative                         no  \n",
       "4           negative                        yes  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1bc0413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Захарова назвала отъезд Цимбалюка из России синдромом Бабченко-Гордона. Много лет, живя в Москве, кричать про российско-украинскую войну, не вылезать из московских ресторанов, выпускать провокационно-фейковые помои в интернете, на все вопросы Чего же ты мучаешься в тылу врага и не пора ли вернуться к своим на передовую? отвечать бессвязным мычанием, а потом придумать байку об угрозе безопасности и статусе заложника. Сопоставимо со свиной кровью Аркадия Бабченко и спецоперациями-коллаборациями Дмитрия Гордона'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data6.loc[4, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbf2cc4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channel_name\n",
       "uniannet             67727\n",
       "radiosvoboda         33220\n",
       "UkrPravdaMainNews    22860\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data6.loc[data6['channel_attitude'] == 'pro-ua', 'channel_name'].value_counts()\n",
    "# data6.loc[3299, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe700f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243a3543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dfbf427",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T14:23:52.096336Z",
     "start_time": "2024-08-23T14:19:54.998295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Russian texts:\n",
      "121346\n",
      "\n",
      "Ukrainian texts:\n",
      "1752\n"
     ]
    }
   ],
   "source": [
    "import langid\n",
    "data6=data6[data6['channel_attitude']=='pro-ua']\n",
    "\n",
    "# Define a function to detect the language\n",
    "def detect_language(text):\n",
    "    lang, _ = langid.classify(text)\n",
    "    return lang\n",
    "\n",
    "# Apply the function to the 'text' column\n",
    "data6['language'] = data6['text'].apply(detect_language)\n",
    "\n",
    "# Filter for Russian (ru) and Ukrainian (uk)\n",
    "df_russian = data6[data6['language'] == 'ru']\n",
    "df_ukrainian = data6[data6['language'] == 'uk']\n",
    "\n",
    "print(\"Russian texts:\")\n",
    "print(len(df_russian))\n",
    "\n",
    "print(\"\\nUkrainian texts:\")\n",
    "print(len(df_ukrainian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c99d8f86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T14:23:52.153641Z",
     "start_time": "2024-08-23T14:23:52.109043Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ukrainian_p=df_ukrainian[df_ukrainian['gpt_sentiment']=='positive']\n",
    "df_ukrainian_neu=df_ukrainian[df_ukrainian['gpt_sentiment']=='neutral']\n",
    "df_ukrainian_neg=df_ukrainian[df_ukrainian['gpt_sentiment']=='negative']\n",
    "selected_columns = [df[['text', 'gpt_sentiment']] for df in [df_ukrainian_neg,df_ukrainian_neu,df_ukrainian_p]]\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "data6_uk = pd.concat(selected_columns, ignore_index=True)\n",
    "data6_uk = data6_uk.rename(columns={'gpt_sentiment': 'label'})\n",
    "\n",
    "data6_uk = data6_uk.rename(columns={'text': 'content'})\n",
    "\n",
    "data6_uk['label'] = data6_uk['label'].str.capitalize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c0d4048",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T14:09:41.963400Z",
     "start_time": "2024-08-08T14:09:41.957902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1752"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data6_uk )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "855e0924",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T14:09:43.300942Z",
     "start_time": "2024-08-08T14:09:43.293395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(469, 620, 663)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_ukrainian_neg),len(df_ukrainian_neu),len(df_ukrainian_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f44e19c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T14:23:52.228003Z",
     "start_time": "2024-08-23T14:23:52.174333Z"
    }
   },
   "outputs": [],
   "source": [
    "seed=42\n",
    "df_russian_p=df_russian[df_russian['gpt_sentiment']=='positive'].sample(n=542,random_state=seed)\n",
    "df_russian_neu=df_russian[df_russian['gpt_sentiment']=='neutral'].sample(n=2220,random_state=seed)\n",
    "df_russian_neg=df_russian[df_russian['gpt_sentiment']=='negative'].sample(n=1180,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d5a6fc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T14:23:52.249808Z",
     "start_time": "2024-08-23T14:23:52.239009Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_columns = [df[['text', 'gpt_sentiment']] for df in [df_russian_neg,df_russian_neu,df_russian_p]]\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "data6_ru = pd.concat(selected_columns, ignore_index=True)\n",
    "data6_ru = data6_ru.rename(columns={'gpt_sentiment': 'label'})\n",
    "\n",
    "data6_ru = data6_ru.rename(columns={'text': 'content'})\n",
    "\n",
    "data6_ru['label'] = data6_ru['label'].str.capitalize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39f4f4c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T10:25:19.092282Z",
     "start_time": "2024-08-27T09:31:27.236205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error translating text: Соледар - это такая абсолютная... - Request exception can happen due to an api connection error. Please check your connection and try again\n",
      "Error translating text: Главное за день: - Суд в Босто... - Request exception can happen due to an api connection error. Please check your connection and try again\n",
      "                                             content  \\\n",
      "0  Военные почти год строили дом своего начальник...   \n",
      "1  День Победы из мемориального события и факта л...   \n",
      "2  США против общего запрета на выдачу виз россия...   \n",
      "3  В Швеции убили критика Кадырова, на которого у...   \n",
      "4   Войска рф скинули взрывчатку на людей, которы...   \n",
      "\n",
      "                                  content_translated  \n",
      "0  Військові майже рік будували будинок свого нач...  \n",
      "1  День Перемоги з меморіальної події та факту ос...  \n",
      "2  США проти загальної заборони видачу віз росіян...  \n",
      "3  У Швеції вбили критика Кадирова, на якого вже ...  \n",
      "4  Війська Росії скинули вибухівку на людей, які ...  \n"
     ]
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# Initialize the translator\n",
    "translator = GoogleTranslator(source='russian', target='ukrainian')\n",
    "\n",
    "# Function to translate text\n",
    "def translate_text(text):\n",
    "    try:\n",
    "        return translator.translate(text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error translating text: {text[:30]}... - {e}\")\n",
    "        return None\n",
    "\n",
    "# Apply the translation to the 'content' column and create a new 'content_translated' column\n",
    "data6_ru['content_translated'] = data6_ru['content'].apply(translate_text)\n",
    "\n",
    "# Display the first few rows to verify the translation\n",
    "print(data6_ru[['content', 'content_translated']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00e01190",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T10:44:41.397748Z",
     "start_time": "2024-08-28T10:44:41.351955Z"
    }
   },
   "outputs": [],
   "source": [
    "data6_ru_t= data6_ru[['content_translated', 'label']].rename(columns={'content_translated': 'content'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "332daa2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T10:46:01.490966Z",
     "start_time": "2024-08-28T10:46:01.419139Z"
    }
   },
   "outputs": [],
   "source": [
    "data6_ru_t.to_csv('./translated_russian.tsv', sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c022e37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T10:44:46.095497Z",
     "start_time": "2024-08-28T10:44:45.933521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                content     label\n",
      "0                      Шо по відключень енергії в Києві  Negative\n",
      "1     Збудували фізичний захист для енергообʼєктів К...  Positive\n",
      "2     Так я ж тебе задал вопрос. Киев, май, первое п...  Positive\n",
      "3                                                Аварії  Negative\n",
      "4     У вас давно вже щось відпадає,а ви ще до цих п...  Negative\n",
      "...                                                 ...       ...\n",
      "9903  Ще кадри зустрічі Зеленського із Дудою Разом в...  Positive\n",
      "9904  Глава Луганської ОВА: Ситуація почне змінювати...  Positive\n",
      "9905  Усі готові поставити Росію на місце. І після т...  Positive\n",
      "9906  Герой мемов Чіткий паца з Рівного одружився Ав...  Positive\n",
      "9907  Про це сказав прем'єр-міністр Нідерландів Марк...  Positive\n",
      "\n",
      "[9908 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([data, data2,data4,data5,data6_uk,data6_ru_t], ignore_index=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "972d377f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T10:44:56.219931Z",
     "start_time": "2024-08-28T10:44:56.198340Z"
    }
   },
   "outputs": [],
   "source": [
    "label_mapping = {1:2,0:1,'Neutral': 0, 'Negative': 1, 'Positive': 2,'Very Positive':2,'Very Negative':1, 'Mixed':1}\n",
    "df['label'] =df['label'].map(label_mapping)\n",
    "df = df.dropna()\n",
    "df['label'] =df['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76d2018a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T10:44:59.072415Z",
     "start_time": "2024-08-28T10:44:59.066593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3123, 3119, 3663)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=df['label'].values.tolist()\n",
    "labels.count(0),labels.count(1),labels.count(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ed2085f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T10:46:19.421153Z",
     "start_time": "2024-08-28T10:46:19.417413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9087bc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T10:46:23.476771Z",
     "start_time": "2024-08-28T10:46:21.644100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikahelicopter/miniconda3/envs/nika/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, load_metric\n",
    "from sklearn.metrics import roc_auc_score, f1_score, matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f921e42a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T10:46:27.347190Z",
     "start_time": "2024-08-28T10:46:24.350045Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikahelicopter/miniconda3/envs/nika/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model_name =\"seara/rubert-base-cased-russian-sentiment\"\n",
    "#model_name = \"cointegrated/rubert-tiny-sentiment-balanced\" \n",
    "#model_name = \"dardem/xlm-roberta-large-uk-toxicity\"\n",
    "# You can choose a different model if needed\n",
    "#sentiment = pipeline('text-classification',\n",
    "    #model=\"seara/rubert-base-cased-russian-sentiment\", \n",
    "    #return_all_scores=True\n",
    "#)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecf8f531",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T10:46:29.642973Z",
     "start_time": "2024-08-28T10:46:29.574754Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.15, stratify=df['label'], random_state=42)\n",
    "\n",
    "# Convert DataFrame to Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1936184f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T10:46:32.407063Z",
     "start_time": "2024-08-28T10:46:31.736449Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████| 8419/8419 [00:00<00:00, 16736.46 examples/s]\n",
      "Map: 100%|█████████| 1486/1486 [00:00<00:00, 20340.03 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['content'], truncation=True)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5072755",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T10:46:34.028162Z",
     "start_time": "2024-08-28T10:46:33.996663Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2833392b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d0fa8699",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T13:52:51.453873Z",
     "start_time": "2024-08-07T13:52:26.695879Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikahelicopter/miniconda3/envs/nika/lib/python3.9/site-packages/accelerate/accelerator.py:447: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='11412' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   29/11412 00:17 < 1:59:27, 1.59 it/s, Epoch 0.02/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 8.61 GB, other allocations: 9.34 GB, max allowed: 18.13 GB). Tried to allocate 350.24 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 52\u001b[0m\n\u001b[1;32m     41\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     42\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     43\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     55\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m~/miniconda3/envs/nika/lib/python3.9/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nika/lib/python3.9/site-packages/transformers/trainer.py:1917\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1911\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\n\u001b[1;32m   1912\u001b[0m             model\u001b[38;5;241m.\u001b[39mparameters(),\n\u001b[1;32m   1913\u001b[0m             args\u001b[38;5;241m.\u001b[39mmax_grad_norm,\n\u001b[1;32m   1914\u001b[0m         )\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;66;03m# Optimizer step\u001b[39;00m\n\u001b[0;32m-> 1917\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m optimizer_was_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39moptimizer_step_was_skipped\n\u001b[1;32m   1919\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_was_run:\n\u001b[1;32m   1920\u001b[0m     \u001b[38;5;66;03m# Delay optimizer scheduling until metrics are generated\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nika/lib/python3.9/site-packages/accelerate/optimizer.py:170\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator_state\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mXLA:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_state\u001b[38;5;241m.\u001b[39mis_xla_gradients_synced \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nika/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nika/lib/python3.9/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nika/lib/python3.9/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/nika/lib/python3.9/site-packages/torch/optim/adamw.py:188\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    175\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    177\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    178\u001b[0m         group,\n\u001b[1;32m    179\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m         state_steps,\n\u001b[1;32m    186\u001b[0m     )\n\u001b[0;32m--> 188\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/nika/lib/python3.9/site-packages/torch/optim/adamw.py:340\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 340\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nika/lib/python3.9/site-packages/torch/optim/adamw.py:471\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    469\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 471\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    473\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 8.61 GB, other allocations: 9.34 GB, max allowed: 18.13 GB). Tried to allocate 350.24 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,  # Reduced learning rate\n",
    "    per_device_train_batch_size=4,  # Reduced batch size\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,  # Increased number of epochs\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,  # Load the best model at the end of training\n",
    "    metric_for_best_model=\"eval_loss\",  # Monitor eval_loss to find the best model\n",
    "    report_to=[]\n",
    ")\n",
    "\n",
    "# Define compute_metrics function\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "\n",
    "    # Apply softmax to get probabilities\n",
    "    probs = np.exp(p.predictions) / np.exp(p.predictions).sum(-1, keepdims=True)\n",
    "    \n",
    "    precision_metric = load_metric(\"precision\")\n",
    "    recall_metric = load_metric(\"recall\")\n",
    "    precision = precision_metric.compute(predictions=preds, references=labels, average='weighted')\n",
    "    recall = recall_metric.compute(predictions=preds, references=labels, average='weighted')\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    mcc = matthews_corrcoef(labels, preds)\n",
    "    auroc = roc_auc_score(labels, probs, multi_class='ovr', average='weighted')\n",
    "    return {\n",
    "        'precision': precision['precision'],\n",
    "        'recall': recall['recall'],\n",
    "        'f1': f1,\n",
    "        'mcc': mcc,\n",
    "        'auroc': auroc,\n",
    "    }\n",
    "\n",
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Print the evaluation results\n",
    "print(eval_results)\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained('./fine_tuned_model5_tuwr_ukr_ru')\n",
    "tokenizer.save_pretrained('./fine_tuned_model5_tuwr_ukr_ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c7ef0b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T16:34:05.664713Z",
     "start_time": "2024-08-28T10:47:13.185464Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikahelicopter/miniconda3/envs/nika/lib/python3.9/site-packages/transformers/training_args.py:1331: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of 🤗 Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n",
      "/Users/nikahelicopter/miniconda3/envs/nika/lib/python3.9/site-packages/accelerate/accelerator.py:447: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8416' max='8416' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8416/8416 5:45:17, Epoch 7/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>Auroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.894900</td>\n",
       "      <td>0.789165</td>\n",
       "      <td>0.658359</td>\n",
       "      <td>0.652759</td>\n",
       "      <td>0.653390</td>\n",
       "      <td>0.480374</td>\n",
       "      <td>0.826137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.518200</td>\n",
       "      <td>0.950850</td>\n",
       "      <td>0.658617</td>\n",
       "      <td>0.656797</td>\n",
       "      <td>0.656154</td>\n",
       "      <td>0.484391</td>\n",
       "      <td>0.828755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.380300</td>\n",
       "      <td>1.909476</td>\n",
       "      <td>0.644619</td>\n",
       "      <td>0.642665</td>\n",
       "      <td>0.641334</td>\n",
       "      <td>0.462376</td>\n",
       "      <td>0.812491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>2.285976</td>\n",
       "      <td>0.653293</td>\n",
       "      <td>0.651413</td>\n",
       "      <td>0.651252</td>\n",
       "      <td>0.476245</td>\n",
       "      <td>0.804328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>2.390991</td>\n",
       "      <td>0.650811</td>\n",
       "      <td>0.650740</td>\n",
       "      <td>0.650216</td>\n",
       "      <td>0.474282</td>\n",
       "      <td>0.803028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/tvpnk3c156l650kh37r9m9yw0000gq/T/ipykernel_16665/2639112635.py:19: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  precision_metric = load_metric(\"precision\")\n",
      "Checkpoint destination directory ./results/checkpoint-1052 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2105 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-3157 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-4210 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-5262 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-6315 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 01:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7891645431518555, 'eval_precision': 0.6583590330924717, 'eval_recall': 0.6527590847913862, 'eval_f1': 0.653389820987069, 'eval_mcc': 0.4803736162256301, 'eval_auroc': 0.8261368400844703, 'eval_runtime': 90.5158, 'eval_samples_per_second': 16.417, 'eval_steps_per_second': 4.11, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_model6_transl/tokenizer_config.json',\n",
       " './fine_tuned_model6_transl/special_tokens_map.json',\n",
       " './fine_tuned_model6_transl/vocab.txt',\n",
       " './fine_tuned_model6_transl/added_tokens.json',\n",
       " './fine_tuned_model6_transl/tokenizer.json')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef, roc_auc_score\n",
    "from datasets import load_metric\n",
    "import torch\n",
    "\n",
    "# Ensure the dataset contains the correct columns\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'label'])\n",
    "val_dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'label'])\n",
    "\n",
    "# Define compute_metrics function\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "\n",
    "    # Apply softmax to get probabilities\n",
    "    probs = np.exp(p.predictions) / np.exp(p.predictions).sum(-1, keepdims=True)\n",
    "\n",
    "    precision_metric = load_metric(\"precision\")\n",
    "    recall_metric = load_metric(\"recall\")\n",
    "    precision = precision_metric.compute(predictions=preds, references=labels, average='weighted')\n",
    "    recall = recall_metric.compute(predictions=preds, references=labels, average='weighted')\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    mcc = matthews_corrcoef(labels, preds)\n",
    "    auroc = roc_auc_score(labels, probs, multi_class='ovr', average='weighted')\n",
    "    return {\n",
    "        'precision': precision['precision'],\n",
    "        'recall': recall['recall'],\n",
    "        'f1': f1,\n",
    "        'mcc': mcc,\n",
    "        'auroc': auroc,\n",
    "    }\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=4,  # Reduced batch size\n",
    "    per_device_eval_batch_size=4,  # Reduced batch size\n",
    "    num_train_epochs=8,  # Reduce number of epochs\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    report_to=[],\n",
    "    gradient_accumulation_steps=2,  # Accumulate gradients over 2 steps\n",
    "    no_cuda=True,  # Force training on CPU\n",
    ")\n",
    "\n",
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Function to clear memory after evaluation\n",
    "def clear_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        # For MPS (Apple Silicon) backend\n",
    "        import gc\n",
    "        gc.collect()\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "clear_memory()  # Clear memory manually if needed\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "clear_memory()  # Clear memory after evaluation\n",
    "\n",
    "# Print the evaluation results\n",
    "print(eval_results)\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained('./fine_tuned_model6_transl')\n",
    "tokenizer.save_pretrained('./fine_tuned_model6_transl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386d9910",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cointegrated\n",
    "/\n",
    "rubert-tiny-sentiment-balanced \n",
    "\n",
    "\n",
    "\n",
    "YaraKyrychenko\n",
    "/\n",
    "ukraine-war-pov\n",
    "\n",
    "\n",
    "dardem\n",
    "/\n",
    "xlm-roberta-large-uk-toxicity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ucu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
