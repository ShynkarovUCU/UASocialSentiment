{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzGGQtbRE5EP"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install safetensors --quiet\n",
    "!pip install wandb --quiet \n",
    "!pip install optuna --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pandas --quiet\n",
    "!pip install matplotlib --quiet\n",
    "!pip install transformers --quiet\n",
    "!pip install scikit-learn --quiet\n",
    "!pip install pyarrow --quiet\n",
    "!pip install transformers[torch] --quiet\n",
    "!pip install accelerate --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshynkarov-pn\u001b[0m (\u001b[33mshynkarov-pn-ukrainian-catholic-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250420_102923-diukwm42</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shynkarov-pn-ukrainian-catholic-university/ukrainian-sentiment/runs/diukwm42' target=\"_blank\">roberta-ukrainian-sentiment</a></strong> to <a href='https://wandb.ai/shynkarov-pn-ukrainian-catholic-university/ukrainian-sentiment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shynkarov-pn-ukrainian-catholic-university/ukrainian-sentiment' target=\"_blank\">https://wandb.ai/shynkarov-pn-ukrainian-catholic-university/ukrainian-sentiment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shynkarov-pn-ukrainian-catholic-university/ukrainian-sentiment/runs/diukwm42' target=\"_blank\">https://wandb.ai/shynkarov-pn-ukrainian-catholic-university/ukrainian-sentiment/runs/diukwm42</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/shynkarov-pn-ukrainian-catholic-university/ukrainian-sentiment/runs/diukwm42?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f1ea4d94610>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"ukrainian-sentiment\",  # Name your project\n",
    "    name=\"roberta-ukrainian-sentiment\",  # Optional run name\n",
    "    tags=[\"roberta\", \"ukrainian\", \"sentiment\"],  # Optional tags for filtering\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_CkWcO5mESa1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "import optuna\n",
    "\n",
    "from transformers import pipeline, BertConfig, BertForSequenceClassification, BertTokenizer\n",
    "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2UyJveV-EXQ1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKV2OfTME6rO"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fWCwE3qcEXOX"
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('final_17042025.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 791
    },
    "id": "mgM9FDSoEXMI",
    "outputId": "998eb672-67e4-46d6-b900-23c42eaad5a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_id</th>\n",
       "      <th>document_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>annotator_sentiment</th>\n",
       "      <th>is_ck_annotation</th>\n",
       "      <th>response_timestamp</th>\n",
       "      <th>document_content</th>\n",
       "      <th>annotation_date</th>\n",
       "      <th>username</th>\n",
       "      <th>unique_document_id</th>\n",
       "      <th>language_wc</th>\n",
       "      <th>document_length</th>\n",
       "      <th>gpt_labels_v1</th>\n",
       "      <th>language_gpt</th>\n",
       "      <th>language_manual</th>\n",
       "      <th>language</th>\n",
       "      <th>stratification_label</th>\n",
       "      <th>df_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>277133851</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-09T23:23:07.220881</td>\n",
       "      <td>⚡️Українська делегація відправилася на перемов...</td>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>O</td>\n",
       "      <td>1_1</td>\n",
       "      <td>uk</td>\n",
       "      <td>67</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Ukrainian</td>\n",
       "      <td>ukrainian</td>\n",
       "      <td>ua</td>\n",
       "      <td>neutral_ua</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1065283664</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-09T23:44:28.262307</td>\n",
       "      <td>Вибухи на Одещині, попередньо — ППО.</td>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>A</td>\n",
       "      <td>2_1</td>\n",
       "      <td>uk</td>\n",
       "      <td>36</td>\n",
       "      <td>negative</td>\n",
       "      <td>Ukrainian</td>\n",
       "      <td>ukrainian</td>\n",
       "      <td>ua</td>\n",
       "      <td>neutral_ua</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1065283664</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-09T23:45:00.503098</td>\n",
       "      <td>А что делать тем ,кто лишился своего жилья ,по...</td>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>A</td>\n",
       "      <td>3_1</td>\n",
       "      <td>ru</td>\n",
       "      <td>177</td>\n",
       "      <td>negative</td>\n",
       "      <td>Code-mixed</td>\n",
       "      <td>russian</td>\n",
       "      <td>ru</td>\n",
       "      <td>negative_ru</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1065283664</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-09T23:46:33.265766</td>\n",
       "      <td>Тогда учись быстро бегать. Для меня вопрос сло...</td>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>A</td>\n",
       "      <td>4_1</td>\n",
       "      <td>ru</td>\n",
       "      <td>103</td>\n",
       "      <td>negative</td>\n",
       "      <td>Code-mixed</td>\n",
       "      <td>russian</td>\n",
       "      <td>ru</td>\n",
       "      <td>negative_ru</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1065283664</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-09T23:46:38.993496</td>\n",
       "      <td>Добрий день</td>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>A</td>\n",
       "      <td>5_1</td>\n",
       "      <td>uk</td>\n",
       "      <td>11</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Ukrainian</td>\n",
       "      <td>russian</td>\n",
       "      <td>ua</td>\n",
       "      <td>neutral_ua</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12219</th>\n",
       "      <td>13028</td>\n",
       "      <td>8948</td>\n",
       "      <td>467130971</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-04T08:02:37.362562</td>\n",
       "      <td>Краще \"повинна бути зручнішою, ніж Uber чи Boo...</td>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>D</td>\n",
       "      <td>8948_0</td>\n",
       "      <td>uk</td>\n",
       "      <td>51</td>\n",
       "      <td>positive</td>\n",
       "      <td>Code-mixed</td>\n",
       "      <td>ukrainian</td>\n",
       "      <td>ua</td>\n",
       "      <td>negative_ua</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12220</th>\n",
       "      <td>13029</td>\n",
       "      <td>2094</td>\n",
       "      <td>467130971</td>\n",
       "      <td>mixed</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-04T08:03:35.792932</td>\n",
       "      <td>Увага! З деяких інтернет джерел шириться інфор...</td>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>D</td>\n",
       "      <td>2094_0</td>\n",
       "      <td>uk</td>\n",
       "      <td>402</td>\n",
       "      <td>positive</td>\n",
       "      <td>Ukrainian</td>\n",
       "      <td>ukrainian</td>\n",
       "      <td>ua</td>\n",
       "      <td>mixed_ua</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12221</th>\n",
       "      <td>13030</td>\n",
       "      <td>5013</td>\n",
       "      <td>467130971</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-04T08:03:42.008533</td>\n",
       "      <td>Питання, цей сертифікат можна вже використовув...</td>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>D</td>\n",
       "      <td>5013_0</td>\n",
       "      <td>uk</td>\n",
       "      <td>113</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Ukrainian</td>\n",
       "      <td>ukrainian</td>\n",
       "      <td>ua</td>\n",
       "      <td>neutral_ua</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12222</th>\n",
       "      <td>13031</td>\n",
       "      <td>4572</td>\n",
       "      <td>467130971</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-04T08:03:48.251166</td>\n",
       "      <td>На Вугледарському напрямку загинув Рома Іванен...</td>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>D</td>\n",
       "      <td>4572_0</td>\n",
       "      <td>uk</td>\n",
       "      <td>114</td>\n",
       "      <td>negative</td>\n",
       "      <td>Ukrainian</td>\n",
       "      <td>ukrainian</td>\n",
       "      <td>ua</td>\n",
       "      <td>negative_ua</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12223</th>\n",
       "      <td>13035</td>\n",
       "      <td>9934</td>\n",
       "      <td>277133851</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-05 21:07:45.024999</td>\n",
       "      <td>*_Управление «УКРАИНЫ» и «РФ» захвачено иудеям...</td>\n",
       "      <td>2025-04-05</td>\n",
       "      <td>O</td>\n",
       "      <td>9934_0</td>\n",
       "      <td>ru</td>\n",
       "      <td>5749</td>\n",
       "      <td>negative</td>\n",
       "      <td>Code-mixed</td>\n",
       "      <td>surzhyk</td>\n",
       "      <td>mixed</td>\n",
       "      <td>negative_mixed</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12224 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       response_id  document_id     user_id annotator_sentiment  \\\n",
       "0                1            1   277133851             neutral   \n",
       "1                3            2  1065283664             neutral   \n",
       "2                4            3  1065283664            negative   \n",
       "3                5            4  1065283664            negative   \n",
       "4                6            5  1065283664             neutral   \n",
       "...            ...          ...         ...                 ...   \n",
       "12219        13028         8948   467130971            negative   \n",
       "12220        13029         2094   467130971               mixed   \n",
       "12221        13030         5013   467130971             neutral   \n",
       "12222        13031         4572   467130971            negative   \n",
       "12223        13035         9934   277133851            negative   \n",
       "\n",
       "       is_ck_annotation          response_timestamp  \\\n",
       "0                     1  2025-03-09T23:23:07.220881   \n",
       "1                     1  2025-03-09T23:44:28.262307   \n",
       "2                     1  2025-03-09T23:45:00.503098   \n",
       "3                     1  2025-03-09T23:46:33.265766   \n",
       "4                     1  2025-03-09T23:46:38.993496   \n",
       "...                 ...                         ...   \n",
       "12219                 0  2025-04-04T08:02:37.362562   \n",
       "12220                 0  2025-04-04T08:03:35.792932   \n",
       "12221                 0  2025-04-04T08:03:42.008533   \n",
       "12222                 0  2025-04-04T08:03:48.251166   \n",
       "12223                 0  2025-04-05 21:07:45.024999   \n",
       "\n",
       "                                        document_content annotation_date  \\\n",
       "0      ⚡️Українська делегація відправилася на перемов...      2025-03-09   \n",
       "1                   Вибухи на Одещині, попередньо — ППО.      2025-03-09   \n",
       "2      А что делать тем ,кто лишился своего жилья ,по...      2025-03-09   \n",
       "3      Тогда учись быстро бегать. Для меня вопрос сло...      2025-03-09   \n",
       "4                                            Добрий день      2025-03-09   \n",
       "...                                                  ...             ...   \n",
       "12219  Краще \"повинна бути зручнішою, ніж Uber чи Boo...      2025-04-04   \n",
       "12220  Увага! З деяких інтернет джерел шириться інфор...      2025-04-04   \n",
       "12221  Питання, цей сертифікат можна вже використовув...      2025-04-04   \n",
       "12222  На Вугледарському напрямку загинув Рома Іванен...      2025-04-04   \n",
       "12223  *_Управление «УКРАИНЫ» и «РФ» захвачено иудеям...      2025-04-05   \n",
       "\n",
       "      username unique_document_id language_wc  document_length gpt_labels_v1  \\\n",
       "0            O                1_1          uk               67       neutral   \n",
       "1            A                2_1          uk               36      negative   \n",
       "2            A                3_1          ru              177      negative   \n",
       "3            A                4_1          ru              103      negative   \n",
       "4            A                5_1          uk               11       neutral   \n",
       "...        ...                ...         ...              ...           ...   \n",
       "12219        D             8948_0          uk               51      positive   \n",
       "12220        D             2094_0          uk              402      positive   \n",
       "12221        D             5013_0          uk              113       neutral   \n",
       "12222        D             4572_0          uk              114      negative   \n",
       "12223        O             9934_0          ru             5749      negative   \n",
       "\n",
       "      language_gpt language_manual language stratification_label      df_set  \n",
       "0        Ukrainian       ukrainian       ua           neutral_ua       train  \n",
       "1        Ukrainian       ukrainian       ua           neutral_ua  validation  \n",
       "2       Code-mixed         russian       ru          negative_ru        test  \n",
       "3       Code-mixed         russian       ru          negative_ru       train  \n",
       "4        Ukrainian         russian       ua           neutral_ua       train  \n",
       "...            ...             ...      ...                  ...         ...  \n",
       "12219   Code-mixed       ukrainian       ua          negative_ua       train  \n",
       "12220    Ukrainian       ukrainian       ua             mixed_ua       train  \n",
       "12221    Ukrainian       ukrainian       ua           neutral_ua       train  \n",
       "12222    Ukrainian       ukrainian       ua          negative_ua       train  \n",
       "12223   Code-mixed         surzhyk    mixed       negative_mixed       train  \n",
       "\n",
       "[12224 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.loc[df['annotator_sentiment'] != 'mixed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12224, 18)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Bu6Cu4b9-xy1"
   },
   "outputs": [],
   "source": [
    "splits_df = {}\n",
    "\n",
    "for sett in df.df_set.unique():\n",
    "    splits_df[sett] = df.loc[df['df_set'] == sett].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vV_vaROgEXJx"
   },
   "outputs": [],
   "source": [
    "train_df = splits_df['train']\n",
    "val_df = splits_df['validation']\n",
    "test_df = splits_df['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "c8HuHSCwEXHT"
   },
   "outputs": [],
   "source": [
    "# train_df = train_df.loc[:, ['document_content', 'annotator_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cVE8M2iHEXCk",
    "outputId": "4840ef98-a267-4688-bc34-04f3071a48df"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzIXNfzaE8v8"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels=df.annotator_sentiment.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_pretrained(\n",
    "    \"bert-base-multilingual-cased\",\n",
    "    num_labels=num_labels,\n",
    "    hidden_dropout_prob=0.2,    # Increase from default (typically 0.1)\n",
    "    attention_probs_dropout_prob=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", config=config)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrcwA2QX7q64"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4klJqJAshIc",
    "outputId": "a081c35b-d078-4fdb-aa01-86d950188904"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 31178, 11356, 102]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hello world\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i328WzkRshGF",
    "outputId": "8c9b979f-4e3f-4767-b712-2d96d8e4f80a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.tokenize(\"Hello world\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u82q6w5q0e6f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9JmiIjZYuLnT",
    "outputId": "2627dc47-5385-4c18-974a-65c129590fe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average tokens per document: 47.95983996758837\n",
      "Median tokens per document: 35.0\n",
      "Max tokens per document: 1894\n",
      "Documents exceeding 512 tokens: 40\n"
     ]
    }
   ],
   "source": [
    "token_lengths = []\n",
    "for text in df['document_content']:\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    token_lengths.append(len(tokens))\n",
    "\n",
    "print(f\"Average tokens per document: {np.mean(token_lengths)}\")\n",
    "print(f\"Median tokens per document: {np.median(token_lengths)}\")\n",
    "print(f\"Max tokens per document: {np.max(token_lengths)}\")\n",
    "print(f\"Documents exceeding 512 tokens: {sum(np.array(token_lengths) > 512)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r2kQmcu8uLlD",
    "outputId": "1e2cf619-b2fa-4a2b-bf0c-a1779bb610b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39492"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "h-CRG6pSuLi9"
   },
   "outputs": [],
   "source": [
    "# df['token_lengths'] = token_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 843
    },
    "id": "7d67eJp-sg89",
    "outputId": "1f9f1c2a-31bf-493f-e812-e8ae1409b5b1"
   },
   "outputs": [],
   "source": [
    "# df.loc[df.document_length > 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59NoSzlT1qe0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--zJ_mjH4xxj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MfNxgQ1FBU4"
   },
   "source": [
    "# Training inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "A2tyjT-X4uAs"
   },
   "outputs": [],
   "source": [
    "# Define maximum sequence length (check max length for your specific model)\n",
    "MAX_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9EiZOZGa42Pr"
   },
   "outputs": [],
   "source": [
    "# Function to create data loaders\n",
    "def create_data_loaders(train_dataset, val_dataset, test_dataset, batch_size=16):\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "qxTCmex81qb7"
   },
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512, strategy=\"truncate\"):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.strategy = strategy\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Different strategies for handling long texts\n",
    "        if self.strategy == \"truncate\":\n",
    "            # Simple truncation from the beginning\n",
    "            encoding = self.tokenizer(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=self.max_length,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "        elif self.strategy == \"head_tail\":\n",
    "            # Take first half tokens from beginning, second half from end\n",
    "            tokens = self.tokenizer.tokenize(text)\n",
    "            if len(tokens) > self.max_length - 2:  # Account for special tokens\n",
    "                half_length = (self.max_length - 2) // 2\n",
    "                tokens = tokens[:half_length] + tokens[-half_length:]\n",
    "\n",
    "            encoding = self.tokenizer.encode_plus(\n",
    "                self.tokenizer.convert_tokens_to_string(tokens),\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=self.max_length,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ynBX56tE58fy"
   },
   "outputs": [],
   "source": [
    "# Function to process dataset with chosen strategy\n",
    "def prepare_datasets(train_df, val_df, test_df, tokenizer, max_length=512, strategy=\"truncate\"):\n",
    "    # Encode the sentiment labels\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Fit on the entire dataset to ensure all classes are included\n",
    "    all_sentiments = pd.concat([\n",
    "        train_df['annotator_sentiment'],\n",
    "        val_df['annotator_sentiment'],\n",
    "        test_df['annotator_sentiment']\n",
    "    ])\n",
    "    label_encoder.fit(all_sentiments)\n",
    "\n",
    "    # Transform the labels\n",
    "    train_labels = label_encoder.transform(train_df['annotator_sentiment'])\n",
    "    val_labels = label_encoder.transform(val_df['annotator_sentiment'])\n",
    "    test_labels = label_encoder.transform(test_df['annotator_sentiment'])\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = SentimentDataset(\n",
    "        train_df['document_content'].values,\n",
    "        train_labels,\n",
    "        tokenizer,\n",
    "        max_length,\n",
    "        strategy\n",
    "    )\n",
    "\n",
    "    val_dataset = SentimentDataset(\n",
    "        val_df['document_content'].values,\n",
    "        val_labels,\n",
    "        tokenizer,\n",
    "        max_length,\n",
    "        strategy\n",
    "    )\n",
    "\n",
    "    test_dataset = SentimentDataset(\n",
    "        test_df['document_content'].values,\n",
    "        test_labels,\n",
    "        tokenizer,\n",
    "        max_length,\n",
    "        strategy\n",
    "    )\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "1fU0l-E_1qaE"
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset, label_encoder = prepare_datasets(\n",
    "    train_df, val_df, test_df, tokenizer, MAX_LENGTH, strategy=\"truncate\" #head_tail\n",
    ")\n",
    "\n",
    "train_loader, val_loader, test_loader = create_data_loaders(\n",
    "    train_dataset, val_dataset, test_dataset, batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DbZcu21E1qXu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "trxVesR36AK4"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YN5VffMM6AFu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OYLwHq4R6ADh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OR1bxwd2FDzS"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "cwWm1H-36ABS"
   },
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output\",\n",
    "    learning_rate=1.1735182865186952e-05,             # Common starting point for BERT\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=2,\n",
    "    # per_device_eval_batch_size=32,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.012916490115700903,\n",
    "    save_total_limit=10,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"mbert_augmented\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross entropy  loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: [ 487 3632 3761 1899]\n"
     ]
    }
   ],
   "source": [
    "# Get class distribution\n",
    "class_counts = np.bincount(label_encoder.transform(train_df['annotator_sentiment']))\n",
    "print(\"Class distribution:\", class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate balanced weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(label_encoder.transform(train_df['annotator_sentiment'])),\n",
    "    y=label_encoder.transform(train_df['annotator_sentiment'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_class_index = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(5.020020533880904)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights[mixed_class_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weights[mixed_class_index] *= 1.5  # Additional boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensor\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LABEL_0': 'mixed',\n",
       " 'LABEL_1': 'negative',\n",
       " 'LABEL_2': 'neutral',\n",
       " 'LABEL_3': 'positive'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    'LABEL_0': 'mixed',\n",
    "    'LABEL_1': 'negative',\n",
    "    'LABEL_2': 'neutral',\n",
    "    'LABEL_3': 'positive',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [5.02002053 0.67311399 0.65002659 1.2873881 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedLossTrainer(Trainer):\n",
    "    def __init__(self, class_weights=None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights\n",
    "        \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        \"\"\"Compatible with all Transformers versions\"\"\"\n",
    "        if \"labels\" in inputs:\n",
    "            labels = inputs.pop(\"labels\")\n",
    "        else:\n",
    "            labels = inputs.get(\"labels\")\n",
    "            \n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        if self.class_weights is not None:\n",
    "            # Ensure weights are on the right device\n",
    "            weights = self.class_weights.to(logits.device)\n",
    "            loss_fct = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "        else:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            \n",
    "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = WeightedLossTrainer(\n",
    "    class_weights=class_weights_tensor,\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "BDXn6B705_-7"
   },
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=val_dataset,\n",
    "#     compute_metrics=compute_metrics,\n",
    "#     callbacks=[EarlyStoppingCallback(early_stopping_patience=6)]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tabahqVd5_89"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "2QTDbdnN1qVf",
    "outputId": "b0b1891d-2147-4550-a560-cf7043196cb4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2050' max='3060' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2050/3060 15:29 < 07:38, 2.20 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.384700</td>\n",
       "      <td>1.365499</td>\n",
       "      <td>0.356792</td>\n",
       "      <td>0.338279</td>\n",
       "      <td>0.342576</td>\n",
       "      <td>0.356792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.367500</td>\n",
       "      <td>1.339361</td>\n",
       "      <td>0.453355</td>\n",
       "      <td>0.400239</td>\n",
       "      <td>0.432125</td>\n",
       "      <td>0.453355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.347400</td>\n",
       "      <td>1.294607</td>\n",
       "      <td>0.534370</td>\n",
       "      <td>0.526463</td>\n",
       "      <td>0.525757</td>\n",
       "      <td>0.534370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.286000</td>\n",
       "      <td>1.181867</td>\n",
       "      <td>0.566285</td>\n",
       "      <td>0.569407</td>\n",
       "      <td>0.576040</td>\n",
       "      <td>0.566285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.181000</td>\n",
       "      <td>1.088824</td>\n",
       "      <td>0.591653</td>\n",
       "      <td>0.583431</td>\n",
       "      <td>0.618154</td>\n",
       "      <td>0.591653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.119700</td>\n",
       "      <td>1.039178</td>\n",
       "      <td>0.572013</td>\n",
       "      <td>0.580403</td>\n",
       "      <td>0.620915</td>\n",
       "      <td>0.572013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.047000</td>\n",
       "      <td>1.041806</td>\n",
       "      <td>0.594108</td>\n",
       "      <td>0.599653</td>\n",
       "      <td>0.619175</td>\n",
       "      <td>0.594108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.022400</td>\n",
       "      <td>1.065192</td>\n",
       "      <td>0.588380</td>\n",
       "      <td>0.585365</td>\n",
       "      <td>0.611997</td>\n",
       "      <td>0.588380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.058200</td>\n",
       "      <td>0.985290</td>\n",
       "      <td>0.575286</td>\n",
       "      <td>0.596268</td>\n",
       "      <td>0.640784</td>\n",
       "      <td>0.575286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.992600</td>\n",
       "      <td>1.016773</td>\n",
       "      <td>0.579378</td>\n",
       "      <td>0.591477</td>\n",
       "      <td>0.645369</td>\n",
       "      <td>0.579378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.035200</td>\n",
       "      <td>1.064703</td>\n",
       "      <td>0.572831</td>\n",
       "      <td>0.584022</td>\n",
       "      <td>0.648996</td>\n",
       "      <td>0.572831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.985200</td>\n",
       "      <td>1.071310</td>\n",
       "      <td>0.569558</td>\n",
       "      <td>0.576453</td>\n",
       "      <td>0.638001</td>\n",
       "      <td>0.569558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.947600</td>\n",
       "      <td>0.980728</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.623379</td>\n",
       "      <td>0.662376</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.901500</td>\n",
       "      <td>1.144391</td>\n",
       "      <td>0.594108</td>\n",
       "      <td>0.590149</td>\n",
       "      <td>0.650886</td>\n",
       "      <td>0.594108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.971065</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.643902</td>\n",
       "      <td>0.670869</td>\n",
       "      <td>0.638298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.929400</td>\n",
       "      <td>1.009052</td>\n",
       "      <td>0.573650</td>\n",
       "      <td>0.591145</td>\n",
       "      <td>0.668076</td>\n",
       "      <td>0.573650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.853700</td>\n",
       "      <td>0.974220</td>\n",
       "      <td>0.587561</td>\n",
       "      <td>0.603734</td>\n",
       "      <td>0.660929</td>\n",
       "      <td>0.587561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.929500</td>\n",
       "      <td>0.961680</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.620674</td>\n",
       "      <td>0.674187</td>\n",
       "      <td>0.595745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.824800</td>\n",
       "      <td>0.976520</td>\n",
       "      <td>0.612930</td>\n",
       "      <td>0.633021</td>\n",
       "      <td>0.678902</td>\n",
       "      <td>0.612930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.825600</td>\n",
       "      <td>0.997875</td>\n",
       "      <td>0.627660</td>\n",
       "      <td>0.632842</td>\n",
       "      <td>0.670563</td>\n",
       "      <td>0.627660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.840100</td>\n",
       "      <td>0.972526</td>\n",
       "      <td>0.626023</td>\n",
       "      <td>0.643224</td>\n",
       "      <td>0.674580</td>\n",
       "      <td>0.626023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.882700</td>\n",
       "      <td>0.974962</td>\n",
       "      <td>0.629296</td>\n",
       "      <td>0.640115</td>\n",
       "      <td>0.671060</td>\n",
       "      <td>0.629296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.816600</td>\n",
       "      <td>1.023790</td>\n",
       "      <td>0.599018</td>\n",
       "      <td>0.617280</td>\n",
       "      <td>0.668186</td>\n",
       "      <td>0.599018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.786100</td>\n",
       "      <td>0.976344</td>\n",
       "      <td>0.610475</td>\n",
       "      <td>0.628600</td>\n",
       "      <td>0.674592</td>\n",
       "      <td>0.610475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.737300</td>\n",
       "      <td>0.974494</td>\n",
       "      <td>0.639935</td>\n",
       "      <td>0.653813</td>\n",
       "      <td>0.682297</td>\n",
       "      <td>0.639935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.738300</td>\n",
       "      <td>1.065383</td>\n",
       "      <td>0.630115</td>\n",
       "      <td>0.627658</td>\n",
       "      <td>0.672167</td>\n",
       "      <td>0.630115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.741900</td>\n",
       "      <td>1.019363</td>\n",
       "      <td>0.601473</td>\n",
       "      <td>0.616367</td>\n",
       "      <td>0.661724</td>\n",
       "      <td>0.601473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.759000</td>\n",
       "      <td>0.989018</td>\n",
       "      <td>0.635843</td>\n",
       "      <td>0.647158</td>\n",
       "      <td>0.675369</td>\n",
       "      <td>0.635843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.727400</td>\n",
       "      <td>1.035450</td>\n",
       "      <td>0.637480</td>\n",
       "      <td>0.647123</td>\n",
       "      <td>0.679296</td>\n",
       "      <td>0.637480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.756600</td>\n",
       "      <td>1.020085</td>\n",
       "      <td>0.608838</td>\n",
       "      <td>0.623228</td>\n",
       "      <td>0.669604</td>\n",
       "      <td>0.608838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.680200</td>\n",
       "      <td>1.030025</td>\n",
       "      <td>0.663666</td>\n",
       "      <td>0.665468</td>\n",
       "      <td>0.679935</td>\n",
       "      <td>0.663666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.714100</td>\n",
       "      <td>1.050692</td>\n",
       "      <td>0.613748</td>\n",
       "      <td>0.621149</td>\n",
       "      <td>0.686719</td>\n",
       "      <td>0.613748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.658300</td>\n",
       "      <td>1.005468</td>\n",
       "      <td>0.636661</td>\n",
       "      <td>0.650461</td>\n",
       "      <td>0.679021</td>\n",
       "      <td>0.636661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.681300</td>\n",
       "      <td>1.028691</td>\n",
       "      <td>0.630933</td>\n",
       "      <td>0.643188</td>\n",
       "      <td>0.682464</td>\n",
       "      <td>0.630933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.644100</td>\n",
       "      <td>1.055607</td>\n",
       "      <td>0.629296</td>\n",
       "      <td>0.639268</td>\n",
       "      <td>0.678733</td>\n",
       "      <td>0.629296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.669700</td>\n",
       "      <td>1.043205</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.626071</td>\n",
       "      <td>0.677186</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.671400</td>\n",
       "      <td>1.016858</td>\n",
       "      <td>0.636661</td>\n",
       "      <td>0.647318</td>\n",
       "      <td>0.674729</td>\n",
       "      <td>0.636661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.636000</td>\n",
       "      <td>1.053700</td>\n",
       "      <td>0.640753</td>\n",
       "      <td>0.646204</td>\n",
       "      <td>0.669532</td>\n",
       "      <td>0.640753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.597800</td>\n",
       "      <td>1.065707</td>\n",
       "      <td>0.642390</td>\n",
       "      <td>0.651380</td>\n",
       "      <td>0.677518</td>\n",
       "      <td>0.642390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.617700</td>\n",
       "      <td>1.025946</td>\n",
       "      <td>0.639935</td>\n",
       "      <td>0.651046</td>\n",
       "      <td>0.681841</td>\n",
       "      <td>0.639935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.586800</td>\n",
       "      <td>1.067977</td>\n",
       "      <td>0.641571</td>\n",
       "      <td>0.647931</td>\n",
       "      <td>0.662019</td>\n",
       "      <td>0.641571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2050, training_loss=0.8758560348138577, metrics={'train_runtime': 930.3387, 'train_samples_per_second': 105.112, 'train_steps_per_second': 3.289, 'total_flos': 1.7239872143450112e+16, 'train_loss': 0.8758560348138577, 'epoch': 6.699346405228758})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "print(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "7-xpP2jK1qTN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mroberta-ukrainian-sentiment\u001b[0m at: \u001b[34mhttps://wandb.ai/shynkarov-pn-ukrainian-catholic-university/ukrainian-sentiment/runs/vl9tnzbt\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250420_080024-vl9tnzbt/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fp8RRIa5sg6q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Hyper params tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 0.01, 0.1)\n",
    "    \n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results_optuna\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=2,\n",
    "        save_total_limit=10,\n",
    "        # warmup_ratio=0.1,\n",
    "        num_train_epochs=5,\n",
    "        weight_decay=weight_decay,\n",
    "        logging_dir=\"./logs_optuna\",\n",
    "        logging_steps=50,\n",
    "        eval_steps=50,\n",
    "        save_steps=50,\n",
    "        eval_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        report_to=\"wandb\",\n",
    "        run_name=\"optuna\",\n",
    "        metric_for_best_model=\"f1\",\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer and train model\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=6)]\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model and return validation accuracy\n",
    "    eval_results = trainer.evaluate()\n",
    "    return eval_results[\"eval_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 23:10:59,094] A new study created in memory with name: no-name-8513712f-27d0-42a3-b86a-4666b4e6c40c\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1050' max='1450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1050/1450 07:25 < 02:49, 2.35 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.917200</td>\n",
       "      <td>0.742903</td>\n",
       "      <td>0.677864</td>\n",
       "      <td>0.674121</td>\n",
       "      <td>0.693244</td>\n",
       "      <td>0.677864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.724700</td>\n",
       "      <td>0.679379</td>\n",
       "      <td>0.707149</td>\n",
       "      <td>0.706546</td>\n",
       "      <td>0.708010</td>\n",
       "      <td>0.707149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.682300</td>\n",
       "      <td>0.679730</td>\n",
       "      <td>0.708010</td>\n",
       "      <td>0.704029</td>\n",
       "      <td>0.725822</td>\n",
       "      <td>0.708010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.697400</td>\n",
       "      <td>0.661064</td>\n",
       "      <td>0.721792</td>\n",
       "      <td>0.718715</td>\n",
       "      <td>0.726476</td>\n",
       "      <td>0.721792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.666200</td>\n",
       "      <td>0.645199</td>\n",
       "      <td>0.732989</td>\n",
       "      <td>0.730710</td>\n",
       "      <td>0.742404</td>\n",
       "      <td>0.732989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.639100</td>\n",
       "      <td>0.663719</td>\n",
       "      <td>0.717485</td>\n",
       "      <td>0.716716</td>\n",
       "      <td>0.723710</td>\n",
       "      <td>0.717485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.569200</td>\n",
       "      <td>0.678832</td>\n",
       "      <td>0.722653</td>\n",
       "      <td>0.723358</td>\n",
       "      <td>0.726377</td>\n",
       "      <td>0.722653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.538900</td>\n",
       "      <td>0.670532</td>\n",
       "      <td>0.721792</td>\n",
       "      <td>0.719441</td>\n",
       "      <td>0.729942</td>\n",
       "      <td>0.721792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.582400</td>\n",
       "      <td>0.656048</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.722225</td>\n",
       "      <td>0.720930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>0.663014</td>\n",
       "      <td>0.736434</td>\n",
       "      <td>0.734845</td>\n",
       "      <td>0.742807</td>\n",
       "      <td>0.736434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.562900</td>\n",
       "      <td>0.652534</td>\n",
       "      <td>0.726960</td>\n",
       "      <td>0.726010</td>\n",
       "      <td>0.731966</td>\n",
       "      <td>0.726960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.530200</td>\n",
       "      <td>0.657117</td>\n",
       "      <td>0.735573</td>\n",
       "      <td>0.733983</td>\n",
       "      <td>0.742231</td>\n",
       "      <td>0.735573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.476500</td>\n",
       "      <td>0.677330</td>\n",
       "      <td>0.731266</td>\n",
       "      <td>0.729915</td>\n",
       "      <td>0.732986</td>\n",
       "      <td>0.731266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.433600</td>\n",
       "      <td>0.685782</td>\n",
       "      <td>0.741602</td>\n",
       "      <td>0.739655</td>\n",
       "      <td>0.744078</td>\n",
       "      <td>0.741602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.454400</td>\n",
       "      <td>0.667982</td>\n",
       "      <td>0.751938</td>\n",
       "      <td>0.751338</td>\n",
       "      <td>0.751899</td>\n",
       "      <td>0.751938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.452900</td>\n",
       "      <td>0.669289</td>\n",
       "      <td>0.739018</td>\n",
       "      <td>0.737966</td>\n",
       "      <td>0.740556</td>\n",
       "      <td>0.739018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.488900</td>\n",
       "      <td>0.668482</td>\n",
       "      <td>0.736434</td>\n",
       "      <td>0.736279</td>\n",
       "      <td>0.736792</td>\n",
       "      <td>0.736434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.387000</td>\n",
       "      <td>0.700487</td>\n",
       "      <td>0.738157</td>\n",
       "      <td>0.737830</td>\n",
       "      <td>0.739906</td>\n",
       "      <td>0.738157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.350400</td>\n",
       "      <td>0.718177</td>\n",
       "      <td>0.743325</td>\n",
       "      <td>0.742481</td>\n",
       "      <td>0.746658</td>\n",
       "      <td>0.743325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.360700</td>\n",
       "      <td>0.724493</td>\n",
       "      <td>0.739018</td>\n",
       "      <td>0.738628</td>\n",
       "      <td>0.739209</td>\n",
       "      <td>0.739018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.372400</td>\n",
       "      <td>0.725968</td>\n",
       "      <td>0.745047</td>\n",
       "      <td>0.744353</td>\n",
       "      <td>0.747551</td>\n",
       "      <td>0.745047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [146/146 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 23:18:29,295] Trial 0 finished with value: 0.7450473729543498 and parameters: {'learning_rate': 1.1735182865186952e-05, 'batch_size': 16, 'weight_decay': 0.012916490115700903}. Best is trial 0 with value: 0.7450473729543498.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='252' max='1450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 252/1450 01:45 < 08:26, 2.36 it/s, Epoch 0.86/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.454600</td>\n",
       "      <td>0.820859</td>\n",
       "      <td>0.712317</td>\n",
       "      <td>0.710457</td>\n",
       "      <td>0.728403</td>\n",
       "      <td>0.712317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.390800</td>\n",
       "      <td>0.819037</td>\n",
       "      <td>0.727821</td>\n",
       "      <td>0.727423</td>\n",
       "      <td>0.732244</td>\n",
       "      <td>0.727821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.339600</td>\n",
       "      <td>0.795487</td>\n",
       "      <td>0.716624</td>\n",
       "      <td>0.714898</td>\n",
       "      <td>0.728954</td>\n",
       "      <td>0.716624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.389900</td>\n",
       "      <td>0.819856</td>\n",
       "      <td>0.712317</td>\n",
       "      <td>0.713834</td>\n",
       "      <td>0.720759</td>\n",
       "      <td>0.712317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.374800</td>\n",
       "      <td>0.763311</td>\n",
       "      <td>0.729543</td>\n",
       "      <td>0.729156</td>\n",
       "      <td>0.729498</td>\n",
       "      <td>0.729543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and run the Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 1.1735182865186952e-05, 'batch_size': 16, 'weight_decay': 0.012916490115700903}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters: {'learning_rate': 1.1735182865186952e-05, 'batch_size': 16, 'weight_decay': 0.012916490115700903}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1.1735182865186952e-05,\n",
       " 'batch_size': 16,\n",
       " 'weight_decay': 0.012916490115700903}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "predictions = trainer.predict(test_dataset)\n",
    "preds = np.argmax(predictions.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = label_encoder.transform(test_df['annotator_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mixed', 'negative', 'neutral', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.05      0.09        60\n",
      "           1       0.71      0.75      0.73       455\n",
      "           2       0.65      0.67      0.66       471\n",
      "           3       0.65      0.68      0.66       237\n",
      "\n",
      "    accuracy                           0.67      1223\n",
      "   macro avg       0.65      0.54      0.53      1223\n",
      "weighted avg       0.67      0.67      0.66      1223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "print(classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.32      0.32        60\n",
      "           1       0.76      0.70      0.73       455\n",
      "           2       0.64      0.75      0.69       471\n",
      "           3       0.72      0.59      0.65       237\n",
      "\n",
      "    accuracy                           0.68      1223\n",
      "   macro avg       0.61      0.59      0.59      1223\n",
      "weighted avg       0.68      0.68      0.68      1223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report -- second try\n",
    "print(classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.03      0.06        60\n",
      "           1       0.74      0.76      0.75       455\n",
      "           2       0.66      0.79      0.72       471\n",
      "           3       0.76      0.61      0.68       237\n",
      "\n",
      "    accuracy                           0.71      1223\n",
      "   macro avg       0.62      0.55      0.55      1223\n",
      "weighted avg       0.69      0.71      0.69      1223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report -- third try\n",
    "print(classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.02      0.03        60\n",
      "           1       0.72      0.75      0.74       455\n",
      "           2       0.68      0.77      0.72       471\n",
      "           3       0.71      0.64      0.67       237\n",
      "\n",
      "    accuracy                           0.70      1223\n",
      "   macro avg       0.56      0.54      0.54      1223\n",
      "weighted avg       0.68      0.70      0.68      1223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report -- fourth try\n",
    "print(classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.84      0.77       455\n",
      "           1       0.72      0.69      0.70       471\n",
      "           2       0.79      0.63      0.70       237\n",
      "\n",
      "    accuracy                           0.73      1163\n",
      "   macro avg       0.74      0.72      0.73      1163\n",
      "weighted avg       0.74      0.73      0.73      1163\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report -- fifth try\n",
    "print(classification_report(test_labels, preds))\n",
    "# trainer.save_model('best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report -- sixth try, mixed class with cross entropy\n",
    "print(classification_report(test_labels, preds))\n",
    "# trainer.save_model('best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.20      0.28        60\n",
      "           1       0.71      0.77      0.74       455\n",
      "           2       0.69      0.73      0.71       471\n",
      "           3       0.77      0.67      0.72       237\n",
      "\n",
      "    accuracy                           0.71      1223\n",
      "   macro avg       0.66      0.59      0.61      1223\n",
      "weighted avg       0.70      0.71      0.70      1223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report -- seventh try, mixed class with cross entropy\n",
    "print(classification_report(test_labels, preds))\n",
    "# trainer.save_model('best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.20      0.26        60\n",
      "           1       0.73      0.70      0.71       455\n",
      "           2       0.64      0.77      0.70       471\n",
      "           3       0.70      0.55      0.62       237\n",
      "\n",
      "    accuracy                           0.67      1223\n",
      "   macro avg       0.61      0.56      0.57      1223\n",
      "weighted avg       0.67      0.67      0.67      1223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report -- mBERT\n",
    "print(classification_report(test_labels, preds))\n",
    "# trainer.save_model('best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.25      0.22        60\n",
      "           1       0.77      0.61      0.68       455\n",
      "           2       0.64      0.76      0.70       471\n",
      "           3       0.66      0.63      0.64       237\n",
      "\n",
      "    accuracy                           0.65      1223\n",
      "   macro avg       0.57      0.56      0.56      1223\n",
      "weighted avg       0.67      0.65      0.66      1223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report -- mBERT w.o augmentations\n",
    "print(classification_report(test_labels, preds))\n",
    "# trainer.save_model('best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
