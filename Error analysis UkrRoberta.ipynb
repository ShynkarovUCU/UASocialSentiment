{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzGGQtbRE5EP"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# wandb.login()\n",
    "\n",
    "# wandb.init(\n",
    "#     project=\"ukrainian-sentiment\",  # Name your project\n",
    "#     name=\"roberta-ukrainian-sentiment\",  # Optional run name\n",
    "#     tags=[\"roberta\", \"ukrainian\", \"sentiment\"],  # Optional tags for filtering\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "_CkWcO5mESa1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "\n",
    "from transformers import pipeline, RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "\n",
    "\n",
    "from safetensors import safe_open\n",
    "from safetensors.torch import load_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2UyJveV-EXQ1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKV2OfTME6rO"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fWCwE3qcEXOX"
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('./data_provided/final_dataset/final_17042025.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 791
    },
    "id": "mgM9FDSoEXMI",
    "outputId": "998eb672-67e4-46d6-b900-23c42eaad5a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_id</th>\n",
       "      <th>document_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>annotator_sentiment</th>\n",
       "      <th>is_ck_annotation</th>\n",
       "      <th>response_timestamp</th>\n",
       "      <th>document_content</th>\n",
       "      <th>annotation_date</th>\n",
       "      <th>username</th>\n",
       "      <th>unique_document_id</th>\n",
       "      <th>language_wc</th>\n",
       "      <th>document_length</th>\n",
       "      <th>gpt_labels_v1</th>\n",
       "      <th>language_gpt</th>\n",
       "      <th>language_manual</th>\n",
       "      <th>language</th>\n",
       "      <th>stratification_label</th>\n",
       "      <th>df_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>277133851</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-09T23:23:07.220881</td>\n",
       "      <td>⚡️Українська делегація відправилася на перемов...</td>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>O</td>\n",
       "      <td>1_1</td>\n",
       "      <td>uk</td>\n",
       "      <td>67</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Ukrainian</td>\n",
       "      <td>ukrainian</td>\n",
       "      <td>ua</td>\n",
       "      <td>neutral_ua</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1065283664</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-09T23:44:28.262307</td>\n",
       "      <td>Вибухи на Одещині, попередньо — ППО.</td>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>A</td>\n",
       "      <td>2_1</td>\n",
       "      <td>uk</td>\n",
       "      <td>36</td>\n",
       "      <td>negative</td>\n",
       "      <td>Ukrainian</td>\n",
       "      <td>ukrainian</td>\n",
       "      <td>ua</td>\n",
       "      <td>neutral_ua</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1065283664</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-09T23:45:00.503098</td>\n",
       "      <td>А что делать тем ,кто лишился своего жилья ,по...</td>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>A</td>\n",
       "      <td>3_1</td>\n",
       "      <td>ru</td>\n",
       "      <td>177</td>\n",
       "      <td>negative</td>\n",
       "      <td>Code-mixed</td>\n",
       "      <td>russian</td>\n",
       "      <td>ru</td>\n",
       "      <td>negative_ru</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1065283664</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-09T23:46:33.265766</td>\n",
       "      <td>Тогда учись быстро бегать. Для меня вопрос сло...</td>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>A</td>\n",
       "      <td>4_1</td>\n",
       "      <td>ru</td>\n",
       "      <td>103</td>\n",
       "      <td>negative</td>\n",
       "      <td>Code-mixed</td>\n",
       "      <td>russian</td>\n",
       "      <td>ru</td>\n",
       "      <td>negative_ru</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1065283664</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-09T23:46:38.993496</td>\n",
       "      <td>Добрий день</td>\n",
       "      <td>2025-03-09</td>\n",
       "      <td>A</td>\n",
       "      <td>5_1</td>\n",
       "      <td>uk</td>\n",
       "      <td>11</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Ukrainian</td>\n",
       "      <td>russian</td>\n",
       "      <td>ua</td>\n",
       "      <td>neutral_ua</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12219</th>\n",
       "      <td>13028</td>\n",
       "      <td>8948</td>\n",
       "      <td>467130971</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-04T08:02:37.362562</td>\n",
       "      <td>Краще \"повинна бути зручнішою, ніж Uber чи Boo...</td>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>D</td>\n",
       "      <td>8948_0</td>\n",
       "      <td>uk</td>\n",
       "      <td>51</td>\n",
       "      <td>positive</td>\n",
       "      <td>Code-mixed</td>\n",
       "      <td>ukrainian</td>\n",
       "      <td>ua</td>\n",
       "      <td>negative_ua</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12220</th>\n",
       "      <td>13029</td>\n",
       "      <td>2094</td>\n",
       "      <td>467130971</td>\n",
       "      <td>mixed</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-04T08:03:35.792932</td>\n",
       "      <td>Увага! З деяких інтернет джерел шириться інфор...</td>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>D</td>\n",
       "      <td>2094_0</td>\n",
       "      <td>uk</td>\n",
       "      <td>402</td>\n",
       "      <td>positive</td>\n",
       "      <td>Ukrainian</td>\n",
       "      <td>ukrainian</td>\n",
       "      <td>ua</td>\n",
       "      <td>mixed_ua</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12221</th>\n",
       "      <td>13030</td>\n",
       "      <td>5013</td>\n",
       "      <td>467130971</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-04T08:03:42.008533</td>\n",
       "      <td>Питання, цей сертифікат можна вже використовув...</td>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>D</td>\n",
       "      <td>5013_0</td>\n",
       "      <td>uk</td>\n",
       "      <td>113</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Ukrainian</td>\n",
       "      <td>ukrainian</td>\n",
       "      <td>ua</td>\n",
       "      <td>neutral_ua</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12222</th>\n",
       "      <td>13031</td>\n",
       "      <td>4572</td>\n",
       "      <td>467130971</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-04T08:03:48.251166</td>\n",
       "      <td>На Вугледарському напрямку загинув Рома Іванен...</td>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>D</td>\n",
       "      <td>4572_0</td>\n",
       "      <td>uk</td>\n",
       "      <td>114</td>\n",
       "      <td>negative</td>\n",
       "      <td>Ukrainian</td>\n",
       "      <td>ukrainian</td>\n",
       "      <td>ua</td>\n",
       "      <td>negative_ua</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12223</th>\n",
       "      <td>13035</td>\n",
       "      <td>9934</td>\n",
       "      <td>277133851</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-05 21:07:45.024999</td>\n",
       "      <td>*_Управление «УКРАИНЫ» и «РФ» захвачено иудеям...</td>\n",
       "      <td>2025-04-05</td>\n",
       "      <td>O</td>\n",
       "      <td>9934_0</td>\n",
       "      <td>ru</td>\n",
       "      <td>5749</td>\n",
       "      <td>negative</td>\n",
       "      <td>Code-mixed</td>\n",
       "      <td>surzhyk</td>\n",
       "      <td>mixed</td>\n",
       "      <td>negative_mixed</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12224 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       response_id  document_id     user_id annotator_sentiment  \\\n",
       "0                1            1   277133851             neutral   \n",
       "1                3            2  1065283664             neutral   \n",
       "2                4            3  1065283664            negative   \n",
       "3                5            4  1065283664            negative   \n",
       "4                6            5  1065283664             neutral   \n",
       "...            ...          ...         ...                 ...   \n",
       "12219        13028         8948   467130971            negative   \n",
       "12220        13029         2094   467130971               mixed   \n",
       "12221        13030         5013   467130971             neutral   \n",
       "12222        13031         4572   467130971            negative   \n",
       "12223        13035         9934   277133851            negative   \n",
       "\n",
       "       is_ck_annotation          response_timestamp  \\\n",
       "0                     1  2025-03-09T23:23:07.220881   \n",
       "1                     1  2025-03-09T23:44:28.262307   \n",
       "2                     1  2025-03-09T23:45:00.503098   \n",
       "3                     1  2025-03-09T23:46:33.265766   \n",
       "4                     1  2025-03-09T23:46:38.993496   \n",
       "...                 ...                         ...   \n",
       "12219                 0  2025-04-04T08:02:37.362562   \n",
       "12220                 0  2025-04-04T08:03:35.792932   \n",
       "12221                 0  2025-04-04T08:03:42.008533   \n",
       "12222                 0  2025-04-04T08:03:48.251166   \n",
       "12223                 0  2025-04-05 21:07:45.024999   \n",
       "\n",
       "                                        document_content annotation_date  \\\n",
       "0      ⚡️Українська делегація відправилася на перемов...      2025-03-09   \n",
       "1                   Вибухи на Одещині, попередньо — ППО.      2025-03-09   \n",
       "2      А что делать тем ,кто лишился своего жилья ,по...      2025-03-09   \n",
       "3      Тогда учись быстро бегать. Для меня вопрос сло...      2025-03-09   \n",
       "4                                            Добрий день      2025-03-09   \n",
       "...                                                  ...             ...   \n",
       "12219  Краще \"повинна бути зручнішою, ніж Uber чи Boo...      2025-04-04   \n",
       "12220  Увага! З деяких інтернет джерел шириться інфор...      2025-04-04   \n",
       "12221  Питання, цей сертифікат можна вже використовув...      2025-04-04   \n",
       "12222  На Вугледарському напрямку загинув Рома Іванен...      2025-04-04   \n",
       "12223  *_Управление «УКРАИНЫ» и «РФ» захвачено иудеям...      2025-04-05   \n",
       "\n",
       "      username unique_document_id language_wc  document_length gpt_labels_v1  \\\n",
       "0            O                1_1          uk               67       neutral   \n",
       "1            A                2_1          uk               36      negative   \n",
       "2            A                3_1          ru              177      negative   \n",
       "3            A                4_1          ru              103      negative   \n",
       "4            A                5_1          uk               11       neutral   \n",
       "...        ...                ...         ...              ...           ...   \n",
       "12219        D             8948_0          uk               51      positive   \n",
       "12220        D             2094_0          uk              402      positive   \n",
       "12221        D             5013_0          uk              113       neutral   \n",
       "12222        D             4572_0          uk              114      negative   \n",
       "12223        O             9934_0          ru             5749      negative   \n",
       "\n",
       "      language_gpt language_manual language stratification_label      df_set  \n",
       "0        Ukrainian       ukrainian       ua           neutral_ua       train  \n",
       "1        Ukrainian       ukrainian       ua           neutral_ua  validation  \n",
       "2       Code-mixed         russian       ru          negative_ru        test  \n",
       "3       Code-mixed         russian       ru          negative_ru       train  \n",
       "4        Ukrainian         russian       ua           neutral_ua       train  \n",
       "...            ...             ...      ...                  ...         ...  \n",
       "12219   Code-mixed       ukrainian       ua          negative_ua       train  \n",
       "12220    Ukrainian       ukrainian       ua             mixed_ua       train  \n",
       "12221    Ukrainian       ukrainian       ua           neutral_ua       train  \n",
       "12222    Ukrainian       ukrainian       ua          negative_ua       train  \n",
       "12223   Code-mixed         surzhyk    mixed       negative_mixed       train  \n",
       "\n",
       "[12224 rows x 18 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12224, 18)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Bu6Cu4b9-xy1"
   },
   "outputs": [],
   "source": [
    "splits_df = {}\n",
    "\n",
    "for sett in df.df_set.unique():\n",
    "    splits_df[sett] = df.loc[df['df_set'] == sett].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vV_vaROgEXJx"
   },
   "outputs": [],
   "source": [
    "train_df = splits_df['train']\n",
    "val_df = splits_df['validation']\n",
    "test_df = splits_df['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8HuHSCwEXHT"
   },
   "outputs": [],
   "source": [
    "# train_df = train_df.loc[:, ['document_content', 'annotator_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cVE8M2iHEXCk",
    "outputId": "4840ef98-a267-4688-bc34-04f3071a48df"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzIXNfzaE8v8"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels=df.annotator_sentiment.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d16674fa6ca4b698cdab1c588606ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model with increased dropout\n",
    "config = RobertaConfig.from_pretrained(\n",
    "    \"youscan/ukr-roberta-base\",\n",
    "    num_labels=num_labels,\n",
    "    hidden_dropout_prob=0.2,    # Increase from default (typically 0.1)\n",
    "    attention_probs_dropout_prob=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HjuHjlCOs0E3",
    "outputId": "aca4b979-3a66-4d97-b007-8f369a341789"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee1a6909faf4016ae94b38682b6d60f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/507M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at youscan/ukr-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12f5016f0ff44229096277d77f6dabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/16.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6218c1e0964e589439a1d8c2a932a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.86M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b29b0d19464f0ab1c86b6ebf87f6ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8f764e3bbf42f58f38c91bb0fb786e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\"youscan/ukr-roberta-base\", num_labels=num_labels)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"youscan/ukr-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrcwA2QX7q64"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4klJqJAshIc",
    "outputId": "a081c35b-d078-4fdb-aa01-86d950188904"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 44, 7802, 83, 4605, 14826, 2]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hello world\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i328WzkRshGF",
    "outputId": "8c9b979f-4e3f-4767-b712-2d96d8e4f80a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.tokenize(\"Hello world\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "u82q6w5q0e6f"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "9EiZOZGa42Pr"
   },
   "outputs": [],
   "source": [
    "# Function to create data loaders\n",
    "def create_data_loaders(train_dataset, val_dataset, test_dataset, batch_size=16):\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "qxTCmex81qb7"
   },
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512, strategy=\"truncate\"):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.strategy = strategy\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Different strategies for handling long texts\n",
    "        if self.strategy == \"truncate\":\n",
    "            # Simple truncation from the beginning\n",
    "            encoding = self.tokenizer(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=self.max_length,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "        elif self.strategy == \"head_tail\":\n",
    "            # Take first half tokens from beginning, second half from end\n",
    "            tokens = self.tokenizer.tokenize(text)\n",
    "            if len(tokens) > self.max_length - 2:  # Account for special tokens\n",
    "                half_length = (self.max_length - 2) // 2\n",
    "                tokens = tokens[:half_length] + tokens[-half_length:]\n",
    "\n",
    "            encoding = self.tokenizer.encode_plus(\n",
    "                self.tokenizer.convert_tokens_to_string(tokens),\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=self.max_length,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ynBX56tE58fy"
   },
   "outputs": [],
   "source": [
    "# Function to process dataset with chosen strategy\n",
    "def prepare_datasets(train_df, val_df, test_df, tokenizer, max_length=512, strategy=\"truncate\"):\n",
    "    # Encode the sentiment labels\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Fit on the entire dataset to ensure all classes are included\n",
    "    all_sentiments = pd.concat([\n",
    "        train_df['annotator_sentiment'],\n",
    "        val_df['annotator_sentiment'],\n",
    "        test_df['annotator_sentiment']\n",
    "    ])\n",
    "    label_encoder.fit(all_sentiments)\n",
    "\n",
    "    # Transform the labels\n",
    "    train_labels = label_encoder.transform(train_df['annotator_sentiment'])\n",
    "    val_labels = label_encoder.transform(val_df['annotator_sentiment'])\n",
    "    test_labels = label_encoder.transform(test_df['annotator_sentiment'])\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = SentimentDataset(\n",
    "        train_df['document_content'].values,\n",
    "        train_labels,\n",
    "        tokenizer,\n",
    "        max_length,\n",
    "        strategy\n",
    "    )\n",
    "\n",
    "    val_dataset = SentimentDataset(\n",
    "        val_df['document_content'].values,\n",
    "        val_labels,\n",
    "        tokenizer,\n",
    "        max_length,\n",
    "        strategy\n",
    "    )\n",
    "\n",
    "    test_dataset = SentimentDataset(\n",
    "        test_df['document_content'].values,\n",
    "        test_labels,\n",
    "        tokenizer,\n",
    "        max_length,\n",
    "        strategy\n",
    "    )\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "1fU0l-E_1qaE"
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset, label_encoder = prepare_datasets(\n",
    "    train_df, val_df, test_df, tokenizer, MAX_LENGTH, strategy=\"truncate\" #head_tail\n",
    ")\n",
    "\n",
    "train_loader, val_loader, test_loader = create_data_loaders(\n",
    "    train_dataset, val_dataset, test_dataset, batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DbZcu21E1qXu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "trxVesR36AK4"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YN5VffMM6AFu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OYLwHq4R6ADh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read model state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./models/model_ukrroberta.safetensors\"\n",
    "# model = safetensors.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = load_file(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(52000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LABEL_0': 'mixed',\n",
       " 'LABEL_1': 'negative',\n",
       " 'LABEL_2': 'neutral',\n",
       " 'LABEL_3': 'positive'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "{\n",
    "    'LABEL_0': 'mixed',\n",
    "    'LABEL_1': 'negative',\n",
    "    'LABEL_2': 'neutral',\n",
    "    'LABEL_3': 'positive',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer):\n",
    "    # Prepare the text input\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=512)\n",
    "    \n",
    "    # Move inputs to the same device as the model\n",
    "    device = model.device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "    \n",
    "    # Map the prediction to sentiment labels\n",
    "    # Assuming the labels are: 0=negative, 1=neutral, 2=positive, 3=mixed (adjust as needed)\n",
    "    sentiment_labels = [\"mixed\", \"negative\", \"neutral\", \"positive\"]\n",
    "    predicted_sentiment = sentiment_labels[predictions.item()]\n",
    "    \n",
    "    return {\n",
    "        'prediction': predictions.item(),\n",
    "        'sentiment': predicted_sentiment,\n",
    "        'scores': torch.nn.functional.softmax(logits, dim=1).tolist()[0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"Це був чудовий день в Україні!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Це був чудовий день в Україні!\n",
      "Predicted sentiment: positive\n",
      "Confidence scores: [0.01219471637159586, 0.0030130271334201097, 0.006361459847539663, 0.9784308075904846]\n"
     ]
    }
   ],
   "source": [
    "result = predict_sentiment(sample_text, model, tokenizer)\n",
    "print(f\"Text: {sample_text}\")\n",
    "print(f\"Predicted sentiment: {result['sentiment']}\")\n",
    "print(f\"Confidence scores: {result['scores']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"Страви були чудові! Але курєр був дууууже повільним і спізнився на 10 хвилин\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Страви були чудові! Але курєр був дууууже повільним і спізнився на 10 хвилин\n",
      "Predicted sentiment: positive\n",
      "Confidence scores: [0.2520085871219635, 0.037474825978279114, 0.014695622026920319, 0.6958209276199341]\n"
     ]
    }
   ],
   "source": [
    "result = predict_sentiment(sample_text, model, tokenizer)\n",
    "print(f\"Text: {sample_text}\")\n",
    "print(f\"Predicted sentiment: {result['sentiment']}\")\n",
    "print(f\"Confidence scores: {result['scores']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected calibration error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, batch_size=16):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Generate classification report\n",
    "    sentiment_labels = [\"mixed\", \"negative\", \"neutral\", \"positive\"]\n",
    "    report = classification_report(\n",
    "        all_labels, \n",
    "        all_preds, \n",
    "        target_names=sentiment_labels,\n",
    "        digits=4\n",
    "    )\n",
    "    \n",
    "    return report, all_labels, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report, y_true_col, y_pred_col = evaluate_model(model, test_loader, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       mixed     0.2143    0.0500    0.0811        60\n",
      "    negative     0.8099    0.6088    0.6951       455\n",
      "     neutral     0.6414    0.8280    0.7229       471\n",
      "    positive     0.6332    0.6920    0.6613       237\n",
      "\n",
      "    accuracy                         0.6819      1223\n",
      "   macro avg     0.5747    0.5447    0.5401      1223\n",
      "weighted avg     0.6816    0.6819    0.6691      1223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sentiment(df, y_true_col, y_pred_col, group_col=\"language\"):\n",
    "    \"\"\"\n",
    "    Evaluate sentiment classification with overall and per-language-group metrics.\n",
    "    \n",
    "    Params:\n",
    "    - df: pd.DataFrame containing predictions and true labels\n",
    "    - y_true_col: column name of true labels (e.g. human annotations)\n",
    "    - y_pred_col: column name of model predictions (e.g. DeepSeek output)\n",
    "    - group_col: column to group by (e.g. 'language')\n",
    "\n",
    "    Returns:\n",
    "    - dict with overall metrics and per-group metrics\n",
    "    \"\"\"\n",
    "    y_true = df[y_true_col]\n",
    "    y_pred = df[y_pred_col]\n",
    "\n",
    "    # Overall metrics\n",
    "    overall_macro = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)\n",
    "    overall_micro = precision_recall_fscore_support(y_true, y_pred, average='micro', zero_division=0)\n",
    "\n",
    "    result = {\n",
    "        \"overall\": {\n",
    "            \"macro\": {\n",
    "                \"precision\": overall_macro[0],\n",
    "                \"recall\": overall_macro[1],\n",
    "                \"f1\": overall_macro[2],\n",
    "            },\n",
    "            \"micro\": {\n",
    "                \"precision\": overall_micro[0],\n",
    "                \"recall\": overall_micro[1],\n",
    "                \"f1\": overall_micro[2],\n",
    "            }\n",
    "        },\n",
    "        \"by_group\": {}\n",
    "    }\n",
    "\n",
    "    # Per-language group metrics\n",
    "    for group_value in df[group_col].unique():\n",
    "        subset = df[df[group_col] == group_value]\n",
    "        if subset.empty:\n",
    "            continue\n",
    "\n",
    "        group_true = subset[y_true_col]\n",
    "        group_pred = subset[y_pred_col]\n",
    "\n",
    "        macro = precision_recall_fscore_support(group_true, group_pred, average='macro', zero_division=0)\n",
    "        micro = precision_recall_fscore_support(group_true, group_pred, average='micro', zero_division=0)\n",
    "\n",
    "        result[\"by_group\"][group_value] = {\n",
    "            \"macro\": {\n",
    "                \"precision\": macro[0],\n",
    "                \"recall\": macro[1],\n",
    "                \"f1\": macro[2],\n",
    "            },\n",
    "            \"micro\": {\n",
    "                \"precision\": micro[0],\n",
    "                \"recall\": micro[1],\n",
    "                \"f1\": micro[2],\n",
    "            }\n",
    "        }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate_sentiment(df_filtered, y_true_col=\"annotator_response\", y_pred_col=\"sentiment_deepseek\")\n",
    "pprint.pprint(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "diploma_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
