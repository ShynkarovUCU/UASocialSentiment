{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecc26498",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T11:28:55.881930Z",
     "start_time": "2025-03-31T11:28:55.454439Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "# Init DeepSeek API client\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-f47fa990b47b47909bd1de489753fd8a\", \n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f033a038",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T11:33:00.717118Z",
     "start_time": "2025-03-31T11:33:00.704626Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_sentiment_deepseek(text):\n",
    "    prompt = f\"\"\"\n",
    "You are an expert in determining the tone of a text. Our task is to determine the emotion (sentiment) that a person puts into a written text as accurately as possible. To do this, I will show you texts from Ukrainian social networks, and you will choose the correct answer regarding the sentiment. The answer options will be as follows:\n",
    "\n",
    "1. Positive -> expressions used that reflect positive emotions (joy, support, admiration, etc.);\n",
    "2. Negative -> expressions used that reflect negative emotions (criticism, sarcasm, condemnation, aggression, doubt, fear, etc.);\n",
    "3. Neutral -> the author does not use either positive or negative expressions (neutral emotion);\n",
    "4. Mixed -> the text contains expressions from both the positive and negative spectrum of emotions (mixed case).\n",
    "\n",
    "It is important that you do not indicate your own guess about the author's sentiment, but find indications of it in specific expressions. I will give a few examples. Examples:\n",
    "\n",
    "\" –ê–≤–∞—Ä—ñ—ó \" -> this short text has a neutral sentiment. Despite the fact that the Ukrainian word \"–ê–≤–∞—Ä—ñ—ó\" often has a negative context, in this case there is no additional information reflecting the sentiment of the author.\n",
    "\" –¢–∞–∫ —è –∂ —Ç–µ–±–µ –∑–∞–¥–∞–ª –≤–æ–ø—Ä–æ—Å. –ö–∏–µ–≤, –º–∞–π, –ø–µ—Ä–≤–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—ç—Ç—Ä–∏–æ—Ç–æ–≤ - –∫–æ–≥–¥–∞ –≤—Å–µ –Ω–µ–±–æ –æ—Å–≤–µ—Ç–∏–ª–∏ —ç—Ç–∏–º - –±—ã–ª–∏ —Ç–∞–º –∏ —Ö22, –∏ –∫–∏–Ω–∂–∞–ª—ã - —Ç–∞–∫ –±—ã–ª–∏ –ø—Ä–∏–ª–µ—Ç—ã —Ç–æ–≥–¥–∞? –ù–µ –±—ã–ª–æ. –í–æ–ø—Ä–æ—Å –∑–∞–ª—É - –ø–æ—á–µ–º—É —Ç–∞–∫ –ø—Ä–æ–∏–∑–æ—à–ª–æ?  –ü—ç—Ç—Ä–∏–æ—Ç—ã —Å–±–∏–≤–∞—é—Ç –≤—Å—é —ç—Ç—É —Å—Ä–∞–Ω—å \" -> this text has a negative sentiment. The author uses expressions that characterize aggression and criticism of the interlocutor.\n",
    "\" –ó–Ω–∏–∫–ª–æ —Å–≤—ñ—Ç–ª–æ —É –°–≤—è—Ç–æ—à–∏–Ω—Å—å–∫–æ–º—É —Ä–∞–π–æ–Ω—ñ. \" -> this text has a neutral sentiment. The fact of the lack of electricity itself is perceived negatively, but the author of the text does not use either positive or negative words / expressions.\n",
    "\" –ü—Ä–æ–±–ª–µ–º–∏ –∑—ñ —Å–≤—ñ—Ç–ª–æ–º –≤ –ö–∏—î–≤—ñ —Ç–∞ –æ–±–ª–∞—Å—Ç—ñ –ø—ñ—Å–ª—è –≤–∏–±—É—Ö—ñ–≤!  \" -> in turn, the following news item has a negative connotation. The author demonstrates his attitude through the word \"–ü—Ä–æ–±–ª–µ–º–∏\" and the exclamation mark \"!\", emphasizing the expression.\n",
    "\" :cry: –í–Ω–∞—Å–ª—ñ–¥–æ–∫ —Ä–∞–∫–µ—Ç–Ω–æ—ó –∞—Ç–∞–∫–∏ –∑–∞—Ñ—ñ–∫—Å–æ–≤–∞–Ω–æ –ø–∞–¥—ñ–Ω–Ω—è —É–ª–∞–º–∫—ñ–≤ –≤ –ü–µ—á–µ—Ä—Å—å–∫–æ–º—É —Ä–∞–π–æ–Ω—ñ –Ω–∞ –¥–∞—Ö –±–∞–≥–∞—Ç–æ–ø–æ–≤–µ—Ä—Ö–æ–≤–æ–≥–æ –∂–∏—Ç–ª–æ–≤–æ–≥–æ –±—É–¥–∏–Ω–∫—É, ‚Äì –ö–ú–í–ê \" -> text with a negative sentiment, which the author demonstrates through the use of the \":cry:\" emoji.\n",
    "\" –ù—É –Ω–æ—Ä–º \" -> this is an example of a positive sentiment. The text itself is not very expressive, but the author clearly demonstrates the emotion of \"approval\" of something, which belongs to the positive spectrum.\n",
    "\" :exclamation:–í –±—ñ–∫ –ö–∏—î–≤–∞ –ø—É—Å–∫–∏ —â–µ –¥–µ–∫—ñ–ª—å–∫–æ—Ö ‚Äò–ö–∏–Ω–¥–∂–∞–ª—ñ–≤‚Äô. –í–æ—Ä–æ–≥ –Ω–∞–º–∞–≥–∞—î—Ç—å—Å—è –ø—Ä–æ–±–∏—Ç–∏ –Ω–∞—à—ñ –ü–ü–û. –ü–æ–∫–∏ –≤—ñ–¥–±–∏–≤–∞—î–º–æ—Å—è, –∞–ª–µ —î –ø–∞–¥—ñ–Ω–Ω—è —É–ª–∞–º–∫—ñ–≤, —Ç–æ–∂ –ø–µ—Ä–µ–±—É–≤–∞—î–º–æ –≤ —É–∫—Ä–∏—Ç—Ç—è—Ö –∞–±–æ —Ö–æ—á–∞ –± –∑–∞ –ø–∞—Ä–æ—é —Å—Ç—ñ–Ω.\" -> this news item is an example of a negative sentiment. The author demonstrates his attitude to the event through the expressions \"–í–æ—Ä–æ–≥ –Ω–∞–º–∞–≥–∞—î—Ç—å—Å—è –ø—Ä–æ–±–∏—Ç–∏ –Ω–∞—à—ñ –ü–ü–û. –ü–æ–∫–∏ –≤—ñ–¥–±–∏–≤–∞—î–º–æ—Å—è, –∞–ª–µ\". \n",
    "\n",
    "Your answer should be only one word. THIS IS IMPORTANT! You must answer exclusively with only one word from the list: [positive, negative, neutral, mixed].\n",
    "\n",
    "Text to classify: \"{text}\"\n",
    "\n",
    "Label:\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a sentiment analysis expert.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"ERROR: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7c4a84c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T11:29:58.112615Z",
     "start_time": "2025-03-31T11:29:57.613267Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_parquet(\"./data_provided/final_dataset/final_17042025.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0ba2dca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T11:29:59.795533Z",
     "start_time": "2025-03-31T11:29:59.786655Z"
    }
   },
   "outputs": [],
   "source": [
    "texts=df.loc[df.df_set == 'test', \"document_content\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebdbb835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1223"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b902a55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8414d04d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T08:51:55.621081Z",
     "start_time": "2025-04-01T08:29:52.556425Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1223/1223 [1:38:17<00:00,  4.82s/it]\n"
     ]
    }
   ],
   "source": [
    "for text in tqdm(texts): \n",
    "    label = predict_sentiment_deepseek(text)\n",
    "    sentiments.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b622d36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f789693e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f26c48e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T08:55:31.032164Z",
     "start_time": "2025-04-01T08:55:31.018162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- positive  \n",
      "\n",
      "(The word \"–∫–æ–º–ø–µ–Ω—Å–∞—Ü—ñ—ó\" (compensations) and the hashtag \"#shrots\" suggest a positive sentiment, as it implies support or relief for those affected.)\n",
      "- negative  \n",
      "\n",
      "(The text conveys a sense of danger or threat through \"–ó–∞–≥—Ä–æ–∑–∞ –∞—Ç–∞–∫–∏,\" which reflects a negative sentiment.)\n",
      "- positive  \n",
      "\n",
      "(The use of the \"üëπüëπüëπ\" emojis, which in this context likely represent intensity or admiration for the special forces, reflects a positive sentiment.)\n",
      "- negative  \n",
      "\n",
      "(The text starts with a neutral/positive tone regarding financial aid and recovery efforts, but ends with the highly negative and vulgar expression \"–•—É–π,\" which drastically shifts the sentiment to negative.)\n"
     ]
    }
   ],
   "source": [
    "sents=['positive', 'negative', 'neutral', 'mixed']\n",
    "sentiment_cleaned=[]\n",
    "for e in sentiments:\n",
    "    if e not in sents:\n",
    "        print('-',e)\n",
    "        if 'mixed' in e:\n",
    "            sentiment_cleaned.append('mixed')\n",
    "        elif 'neutral' in e:\n",
    "            sentiment_cleaned.append('neutral')\n",
    "        elif 'positive' in e:\n",
    "            sentiment_cleaned.append('positive')\n",
    "        elif 'negative' in e:\n",
    "            sentiment_cleaned.append('negative')\n",
    "        else:\n",
    "            sentiment_cleaned.append('neutral')\n",
    "    else:\n",
    "        sentiment_cleaned.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5d3b1e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T08:55:44.502621Z",
     "start_time": "2025-04-01T08:55:44.493702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mixed', 'negative', 'neutral', 'positive'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(sentiment_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35862caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e9abbe9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T09:03:20.139985Z",
     "start_time": "2025-04-01T09:03:20.053451Z"
    }
   },
   "outputs": [],
   "source": [
    "# df=pd.read_csv(\"ua_sentiment_dataset_labeled_lang.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea4475f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.loc[df.df_set=='test'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0969f802",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"sentiment_deepseek\"] = sentiment_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd87f74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6369582992641046"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test.loc[df_test.annotator_sentiment == df_test.sentiment_deepseek]) / df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597c68f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6125bf0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T09:03:20.697759Z",
     "start_time": "2025-04-01T09:03:20.668617Z"
    }
   },
   "outputs": [],
   "source": [
    "# df[\"sentiment_deepseek\"] = sentiment_cleaned\n",
    "# df[\"annotator_response\"] = df[\"annotator_response\"].str.strip().str.lower()\n",
    "# df[\"sentiment_deepseek\"] = df[\"sentiment_deepseek\"].str.strip().str.lower()\n",
    "# df_filtered = df[df[\"annotator_response\"].str.lower() != \"idk\"].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da1f224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_parquet('./data_provided/final_dataset/df_test_set_deepseek.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d65a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5d05f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa796533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59f3d979",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T09:03:21.947737Z",
     "start_time": "2025-04-01T09:03:21.935078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4312, 'Code-mixed'], [1799, 'Russian'], [2924, 'Ukrainian']]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[df_filtered['language'].values.tolist().count(e),e] for e in list(set(df_filtered['language'].values.tolist()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0651113d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T09:03:36.817891Z",
     "start_time": "2025-04-01T09:03:36.625259Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_sentiment(df, y_true_col, y_pred_col, group_col=\"language\"):\n",
    "    \"\"\"\n",
    "    Evaluate sentiment classification with overall and per-language-group metrics.\n",
    "    \n",
    "    Params:\n",
    "    - df: pd.DataFrame containing predictions and true labels\n",
    "    - y_true_col: column name of true labels (e.g. human annotations)\n",
    "    - y_pred_col: column name of model predictions (e.g. DeepSeek output)\n",
    "    - group_col: column to group by (e.g. 'language')\n",
    "\n",
    "    Returns:\n",
    "    - dict with overall metrics and per-group metrics\n",
    "    \"\"\"\n",
    "    y_true = df[y_true_col]\n",
    "    y_pred = df[y_pred_col]\n",
    "\n",
    "    # Overall metrics\n",
    "    overall_macro = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)\n",
    "    overall_micro = precision_recall_fscore_support(y_true, y_pred, average='micro', zero_division=0)\n",
    "\n",
    "    result = {\n",
    "        \"overall\": {\n",
    "            \"macro\": {\n",
    "                \"precision\": overall_macro[0],\n",
    "                \"recall\": overall_macro[1],\n",
    "                \"f1\": overall_macro[2],\n",
    "            },\n",
    "            \"micro\": {\n",
    "                \"precision\": overall_micro[0],\n",
    "                \"recall\": overall_micro[1],\n",
    "                \"f1\": overall_micro[2],\n",
    "            }\n",
    "        },\n",
    "        \"by_group\": {}\n",
    "    }\n",
    "\n",
    "    # Per-language group metrics\n",
    "    for group_value in df[group_col].unique():\n",
    "        subset = df[df[group_col] == group_value]\n",
    "        if subset.empty:\n",
    "            continue\n",
    "\n",
    "        group_true = subset[y_true_col]\n",
    "        group_pred = subset[y_pred_col]\n",
    "\n",
    "        macro = precision_recall_fscore_support(group_true, group_pred, average='macro', zero_division=0)\n",
    "        micro = precision_recall_fscore_support(group_true, group_pred, average='micro', zero_division=0)\n",
    "\n",
    "        result[\"by_group\"][group_value] = {\n",
    "            \"macro\": {\n",
    "                \"precision\": macro[0],\n",
    "                \"recall\": macro[1],\n",
    "                \"f1\": macro[2],\n",
    "            },\n",
    "            \"micro\": {\n",
    "                \"precision\": micro[0],\n",
    "                \"recall\": micro[1],\n",
    "                \"f1\": micro[2],\n",
    "            }\n",
    "        }\n",
    "\n",
    "    return result\n",
    "\n",
    "metrics = evaluate_sentiment(df_test, y_true_col=\"annotator_sentiment\", y_pred_col=\"sentiment_deepseek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf67450c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'by_group': {'mixed': {'macro': {'f1': 0.5913036902601331,\n",
      "                                  'precision': 0.7347222222222223,\n",
      "                                  'recall': 0.5654761904761905},\n",
      "                        'micro': {'f1': 0.6825396825396826,\n",
      "                                  'precision': 0.6825396825396826,\n",
      "                                  'recall': 0.6825396825396826}},\n",
      "              'ru': {'macro': {'f1': 0.48077995989690503,\n",
      "                               'precision': 0.5893144872138629,\n",
      "                               'recall': 0.48601928374655645},\n",
      "                     'micro': {'f1': 0.6498599439775911,\n",
      "                               'precision': 0.6498599439775911,\n",
      "                               'recall': 0.6498599439775911}},\n",
      "              'ua': {'macro': {'f1': 0.5378355276471065,\n",
      "                               'precision': 0.5876203944898655,\n",
      "                               'recall': 0.5704492277790206},\n",
      "                     'micro': {'f1': 0.6276463262764632,\n",
      "                               'precision': 0.6276463262764632,\n",
      "                               'recall': 0.6276463262764632}}},\n",
      " 'overall': {'macro': {'f1': 0.536707384333384,\n",
      "                       'precision': 0.5966201682323178,\n",
      "                       'recall': 0.5566400949020073},\n",
      "             'micro': {'f1': 0.6369582992641046,\n",
      "                       'precision': 0.6369582992641046,\n",
      "                       'recall': 0.6369582992641046}}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655987ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7021aae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diploma_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
