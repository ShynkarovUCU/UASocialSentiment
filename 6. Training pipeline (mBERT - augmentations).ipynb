{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzGGQtbRE5EP"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install safetensors --quiet\n",
    "!pip install wandb --quiet \n",
    "!pip install optuna --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pandas --quiet\n",
    "!pip install matplotlib --quiet\n",
    "!pip install transformers --quiet\n",
    "!pip install scikit-learn --quiet\n",
    "!pip install pyarrow --quiet\n",
    "!pip install transformers[torch] --quiet\n",
    "!pip install accelerate --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshynkarov-pn\u001b[0m (\u001b[33mshynkarov-pn-ukrainian-catholic-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250420_080024-vl9tnzbt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shynkarov-pn-ukrainian-catholic-university/ukrainian-sentiment/runs/vl9tnzbt' target=\"_blank\">roberta-ukrainian-sentiment</a></strong> to <a href='https://wandb.ai/shynkarov-pn-ukrainian-catholic-university/ukrainian-sentiment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shynkarov-pn-ukrainian-catholic-university/ukrainian-sentiment' target=\"_blank\">https://wandb.ai/shynkarov-pn-ukrainian-catholic-university/ukrainian-sentiment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shynkarov-pn-ukrainian-catholic-university/ukrainian-sentiment/runs/vl9tnzbt' target=\"_blank\">https://wandb.ai/shynkarov-pn-ukrainian-catholic-university/ukrainian-sentiment/runs/vl9tnzbt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/shynkarov-pn-ukrainian-catholic-university/ukrainian-sentiment/runs/vl9tnzbt?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f38f0e94350>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"ukrainian-sentiment\",  # Name your project\n",
    "    name=\"roberta-ukrainian-sentiment\",  # Optional run name\n",
    "    tags=[\"roberta\", \"ukrainian\", \"sentiment\"],  # Optional tags for filtering\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_CkWcO5mESa1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "import optuna\n",
    "\n",
    "from transformers import pipeline, BertConfig, BertForSequenceClassification, BertTokenizer\n",
    "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2UyJveV-EXQ1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKV2OfTME6rO"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fWCwE3qcEXOX"
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('df_augmented_full_final.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 791
    },
    "id": "mgM9FDSoEXMI",
    "outputId": "998eb672-67e4-46d6-b900-23c42eaad5a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stratification_label</th>\n",
       "      <th>document_content</th>\n",
       "      <th>language</th>\n",
       "      <th>username</th>\n",
       "      <th>annotator_sentiment</th>\n",
       "      <th>user_id</th>\n",
       "      <th>document_id</th>\n",
       "      <th>document_length</th>\n",
       "      <th>is_ck_annotation</th>\n",
       "      <th>unique_document_id</th>\n",
       "      <th>df_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive_ua</td>\n",
       "      <td>Треба максимальна підтримка, прошу поширення</td>\n",
       "      <td>ua</td>\n",
       "      <td>D</td>\n",
       "      <td>positive</td>\n",
       "      <td>467130971</td>\n",
       "      <td>3347</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>3347_0</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral_ua</td>\n",
       "      <td>Чому на замовлення ватних дисків сьогодні не з...</td>\n",
       "      <td>ua</td>\n",
       "      <td>O</td>\n",
       "      <td>neutral</td>\n",
       "      <td>277133851</td>\n",
       "      <td>1117</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>1117_0</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive_ru</td>\n",
       "      <td>\"Прекрасное настроение наполняет сердце радост...</td>\n",
       "      <td>ru</td>\n",
       "      <td>gpt</td>\n",
       "      <td>positive</td>\n",
       "      <td>-1</td>\n",
       "      <td>23500</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>23500_0</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive_mixed</td>\n",
       "      <td>✨ Отримала подарункові сертифікати на будівель...</td>\n",
       "      <td>mixed</td>\n",
       "      <td>gpt</td>\n",
       "      <td>positive</td>\n",
       "      <td>-1</td>\n",
       "      <td>35734</td>\n",
       "      <td>530</td>\n",
       "      <td>0</td>\n",
       "      <td>35734_0</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative_ua</td>\n",
       "      <td>Трохи несправедливо відносяться до молоді. \"Зн...</td>\n",
       "      <td>ua</td>\n",
       "      <td>gpt</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>13567</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>13567_0</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39487</th>\n",
       "      <td>negative_ru</td>\n",
       "      <td>Дом напротив муз.училища.Фото старое,дома уже нет</td>\n",
       "      <td>ru</td>\n",
       "      <td>D</td>\n",
       "      <td>negative</td>\n",
       "      <td>467130971</td>\n",
       "      <td>10308</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>10308_0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39488</th>\n",
       "      <td>negative_ua</td>\n",
       "      <td>Розумію так. За неявку без поважної причини по...</td>\n",
       "      <td>ua</td>\n",
       "      <td>D</td>\n",
       "      <td>negative</td>\n",
       "      <td>467130971</td>\n",
       "      <td>5930</td>\n",
       "      <td>998</td>\n",
       "      <td>0</td>\n",
       "      <td>5930_0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39489</th>\n",
       "      <td>neutral_ua</td>\n",
       "      <td>фізичне та ментальне відновлення 3️⃣Економічна...</td>\n",
       "      <td>ua</td>\n",
       "      <td>D</td>\n",
       "      <td>neutral</td>\n",
       "      <td>467130971</td>\n",
       "      <td>11410</td>\n",
       "      <td>461</td>\n",
       "      <td>0</td>\n",
       "      <td>11410_0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39490</th>\n",
       "      <td>negative_ua</td>\n",
       "      <td>Німеччина передасть Україні сучасні ППО та рад...</td>\n",
       "      <td>ua</td>\n",
       "      <td>D</td>\n",
       "      <td>negative</td>\n",
       "      <td>467130971</td>\n",
       "      <td>2967</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>2967_0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39491</th>\n",
       "      <td>mixed_mixed</td>\n",
       "      <td>РФ не планує наступу з Білорусі, оскільки пере...</td>\n",
       "      <td>mixed</td>\n",
       "      <td>D</td>\n",
       "      <td>mixed</td>\n",
       "      <td>467130971</td>\n",
       "      <td>1905</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>1905_0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39492 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stratification_label                                   document_content  \\\n",
       "0              positive_ua       Треба максимальна підтримка, прошу поширення   \n",
       "1               neutral_ua  Чому на замовлення ватних дисків сьогодні не з...   \n",
       "2              positive_ru  \"Прекрасное настроение наполняет сердце радост...   \n",
       "3           positive_mixed  ✨ Отримала подарункові сертифікати на будівель...   \n",
       "4              negative_ua  Трохи несправедливо відносяться до молоді. \"Зн...   \n",
       "...                    ...                                                ...   \n",
       "39487          negative_ru  Дом напротив муз.училища.Фото старое,дома уже нет   \n",
       "39488          negative_ua  Розумію так. За неявку без поважної причини по...   \n",
       "39489           neutral_ua  фізичне та ментальне відновлення 3️⃣Економічна...   \n",
       "39490          negative_ua  Німеччина передасть Україні сучасні ППО та рад...   \n",
       "39491          mixed_mixed  РФ не планує наступу з Білорусі, оскільки пере...   \n",
       "\n",
       "      language username annotator_sentiment    user_id  document_id  \\\n",
       "0           ua        D            positive  467130971         3347   \n",
       "1           ua        O             neutral  277133851         1117   \n",
       "2           ru      gpt            positive         -1        23500   \n",
       "3        mixed      gpt            positive         -1        35734   \n",
       "4           ua      gpt            negative         -1        13567   \n",
       "...        ...      ...                 ...        ...          ...   \n",
       "39487       ru        D            negative  467130971        10308   \n",
       "39488       ua        D            negative  467130971         5930   \n",
       "39489       ua        D             neutral  467130971        11410   \n",
       "39490       ua        D            negative  467130971         2967   \n",
       "39491    mixed        D               mixed  467130971         1905   \n",
       "\n",
       "       document_length  is_ck_annotation unique_document_id      df_set  \n",
       "0                   44                 0             3347_0  validation  \n",
       "1                   68                 0             1117_0  validation  \n",
       "2                  101                 0            23500_0  validation  \n",
       "3                  530                 0            35734_0  validation  \n",
       "4                  200                 0            13567_0  validation  \n",
       "...                ...               ...                ...         ...  \n",
       "39487               49                 0            10308_0        test  \n",
       "39488              998                 0             5930_0        test  \n",
       "39489              461                 0            11410_0        test  \n",
       "39490              266                 0             2967_0        test  \n",
       "39491              237                 0             1905_0        test  \n",
       "\n",
       "[39492 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.loc[df['annotator_sentiment'] != 'mixed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39492, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Bu6Cu4b9-xy1"
   },
   "outputs": [],
   "source": [
    "splits_df = {}\n",
    "\n",
    "for sett in df.df_set.unique():\n",
    "    splits_df[sett] = df.loc[df['df_set'] == sett].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vV_vaROgEXJx"
   },
   "outputs": [],
   "source": [
    "train_df = splits_df['train']\n",
    "val_df = splits_df['validation']\n",
    "test_df = splits_df['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8HuHSCwEXHT"
   },
   "outputs": [],
   "source": [
    "# train_df = train_df.loc[:, ['document_content', 'annotator_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cVE8M2iHEXCk",
    "outputId": "4840ef98-a267-4688-bc34-04f3071a48df"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzIXNfzaE8v8"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels=df.annotator_sentiment.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b629d50feba94c878f968b3312110cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = BertConfig.from_pretrained(\n",
    "    \"bert-base-multilingual-cased\",\n",
    "    num_labels=num_labels,\n",
    "    hidden_dropout_prob=0.2,    # Increase from default (typically 0.1)\n",
    "    attention_probs_dropout_prob=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5bbe553bed04dafb82192ec85306ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24535dc7d80c45cdb6a990e28651d55d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9443f3497b334967a416355d39304c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382a1cebb3124deb8f0db518abf96415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", config=config)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrcwA2QX7q64"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4klJqJAshIc",
    "outputId": "a081c35b-d078-4fdb-aa01-86d950188904"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 44, 7802, 83, 4605, 14826, 2]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hello world\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i328WzkRshGF",
    "outputId": "8c9b979f-4e3f-4767-b712-2d96d8e4f80a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.tokenize(\"Hello world\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u82q6w5q0e6f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9JmiIjZYuLnT",
    "outputId": "2627dc47-5385-4c18-974a-65c129590fe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average tokens per document: 47.95983996758837\n",
      "Median tokens per document: 35.0\n",
      "Max tokens per document: 1894\n",
      "Documents exceeding 512 tokens: 40\n"
     ]
    }
   ],
   "source": [
    "token_lengths = []\n",
    "for text in df['document_content']:\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    token_lengths.append(len(tokens))\n",
    "\n",
    "print(f\"Average tokens per document: {np.mean(token_lengths)}\")\n",
    "print(f\"Median tokens per document: {np.median(token_lengths)}\")\n",
    "print(f\"Max tokens per document: {np.max(token_lengths)}\")\n",
    "print(f\"Documents exceeding 512 tokens: {sum(np.array(token_lengths) > 512)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r2kQmcu8uLlD",
    "outputId": "1e2cf619-b2fa-4a2b-bf0c-a1779bb610b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39492"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "h-CRG6pSuLi9"
   },
   "outputs": [],
   "source": [
    "# df['token_lengths'] = token_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 843
    },
    "id": "7d67eJp-sg89",
    "outputId": "1f9f1c2a-31bf-493f-e812-e8ae1409b5b1"
   },
   "outputs": [],
   "source": [
    "# df.loc[df.document_length > 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59NoSzlT1qe0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--zJ_mjH4xxj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MfNxgQ1FBU4"
   },
   "source": [
    "# Training inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "A2tyjT-X4uAs"
   },
   "outputs": [],
   "source": [
    "# Define maximum sequence length (check max length for your specific model)\n",
    "MAX_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9EiZOZGa42Pr"
   },
   "outputs": [],
   "source": [
    "# Function to create data loaders\n",
    "def create_data_loaders(train_dataset, val_dataset, test_dataset, batch_size=16):\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "qxTCmex81qb7"
   },
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512, strategy=\"truncate\"):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.strategy = strategy\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Different strategies for handling long texts\n",
    "        if self.strategy == \"truncate\":\n",
    "            # Simple truncation from the beginning\n",
    "            encoding = self.tokenizer(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=self.max_length,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "        elif self.strategy == \"head_tail\":\n",
    "            # Take first half tokens from beginning, second half from end\n",
    "            tokens = self.tokenizer.tokenize(text)\n",
    "            if len(tokens) > self.max_length - 2:  # Account for special tokens\n",
    "                half_length = (self.max_length - 2) // 2\n",
    "                tokens = tokens[:half_length] + tokens[-half_length:]\n",
    "\n",
    "            encoding = self.tokenizer.encode_plus(\n",
    "                self.tokenizer.convert_tokens_to_string(tokens),\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=self.max_length,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ynBX56tE58fy"
   },
   "outputs": [],
   "source": [
    "# Function to process dataset with chosen strategy\n",
    "def prepare_datasets(train_df, val_df, test_df, tokenizer, max_length=512, strategy=\"truncate\"):\n",
    "    # Encode the sentiment labels\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Fit on the entire dataset to ensure all classes are included\n",
    "    all_sentiments = pd.concat([\n",
    "        train_df['annotator_sentiment'],\n",
    "        val_df['annotator_sentiment'],\n",
    "        test_df['annotator_sentiment']\n",
    "    ])\n",
    "    label_encoder.fit(all_sentiments)\n",
    "\n",
    "    # Transform the labels\n",
    "    train_labels = label_encoder.transform(train_df['annotator_sentiment'])\n",
    "    val_labels = label_encoder.transform(val_df['annotator_sentiment'])\n",
    "    test_labels = label_encoder.transform(test_df['annotator_sentiment'])\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = SentimentDataset(\n",
    "        train_df['document_content'].values,\n",
    "        train_labels,\n",
    "        tokenizer,\n",
    "        max_length,\n",
    "        strategy\n",
    "    )\n",
    "\n",
    "    val_dataset = SentimentDataset(\n",
    "        val_df['document_content'].values,\n",
    "        val_labels,\n",
    "        tokenizer,\n",
    "        max_length,\n",
    "        strategy\n",
    "    )\n",
    "\n",
    "    test_dataset = SentimentDataset(\n",
    "        test_df['document_content'].values,\n",
    "        test_labels,\n",
    "        tokenizer,\n",
    "        max_length,\n",
    "        strategy\n",
    "    )\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "1fU0l-E_1qaE"
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset, label_encoder = prepare_datasets(\n",
    "    train_df, val_df, test_df, tokenizer, MAX_LENGTH, strategy=\"truncate\" #head_tail\n",
    ")\n",
    "\n",
    "train_loader, val_loader, test_loader = create_data_loaders(\n",
    "    train_dataset, val_dataset, test_dataset, batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DbZcu21E1qXu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "trxVesR36AK4"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YN5VffMM6AFu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OYLwHq4R6ADh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OR1bxwd2FDzS"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "cwWm1H-36ABS"
   },
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output\",\n",
    "    learning_rate=1.1735182865186952e-05,             # Common starting point for BERT\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=2,\n",
    "    # per_device_eval_batch_size=32,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.012916490115700903,\n",
    "    save_total_limit=10,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"mbert_augmented\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross entropy  loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: [7850 7535 7522 7708]\n"
     ]
    }
   ],
   "source": [
    "# Get class distribution\n",
    "class_counts = np.bincount(label_encoder.transform(train_df['annotator_sentiment']))\n",
    "print(\"Class distribution:\", class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate balanced weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(label_encoder.transform(train_df['annotator_sentiment'])),\n",
    "    y=label_encoder.transform(train_df['annotator_sentiment'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_class_index = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.975)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights[mixed_class_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weights[mixed_class_index] *= 1.5  # Additional boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensor\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    'LABEL_0': 'mixed',\n",
    "    'LABEL_1': 'negative',\n",
    "    'LABEL_2': 'neutral',\n",
    "    'LABEL_3': 'positive',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [0.975      1.01575979 1.01751529 0.99296186]\n"
     ]
    }
   ],
   "source": [
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedLossTrainer(Trainer):\n",
    "    def __init__(self, class_weights=None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights\n",
    "        \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        \"\"\"Compatible with all Transformers versions\"\"\"\n",
    "        if \"labels\" in inputs:\n",
    "            labels = inputs.pop(\"labels\")\n",
    "        else:\n",
    "            labels = inputs.get(\"labels\")\n",
    "            \n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        if self.class_weights is not None:\n",
    "            # Ensure weights are on the right device\n",
    "            weights = self.class_weights.to(logits.device)\n",
    "            loss_fct = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "        else:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            \n",
    "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = WeightedLossTrainer(\n",
    "    class_weights=class_weights_tensor,\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "BDXn6B705_-7"
   },
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=val_dataset,\n",
    "#     compute_metrics=compute_metrics,\n",
    "#     callbacks=[EarlyStoppingCallback(early_stopping_patience=6)]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tabahqVd5_89"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "2QTDbdnN1qVf",
    "outputId": "b0b1891d-2147-4550-a560-cf7043196cb4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='501' max='9570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 501/9570 07:19 < 2:13:01, 1.14 it/s, Epoch 0.52/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.401700</td>\n",
       "      <td>1.392092</td>\n",
       "      <td>0.261301</td>\n",
       "      <td>0.134260</td>\n",
       "      <td>0.249640</td>\n",
       "      <td>0.261301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.388900</td>\n",
       "      <td>1.377224</td>\n",
       "      <td>0.304024</td>\n",
       "      <td>0.216246</td>\n",
       "      <td>0.372102</td>\n",
       "      <td>0.304024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.372700</td>\n",
       "      <td>1.342104</td>\n",
       "      <td>0.403188</td>\n",
       "      <td>0.364749</td>\n",
       "      <td>0.437582</td>\n",
       "      <td>0.403188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.319300</td>\n",
       "      <td>1.252203</td>\n",
       "      <td>0.503528</td>\n",
       "      <td>0.483366</td>\n",
       "      <td>0.525180</td>\n",
       "      <td>0.503528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.221600</td>\n",
       "      <td>1.135766</td>\n",
       "      <td>0.545597</td>\n",
       "      <td>0.516189</td>\n",
       "      <td>0.565877</td>\n",
       "      <td>0.545597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.146400</td>\n",
       "      <td>1.047032</td>\n",
       "      <td>0.579828</td>\n",
       "      <td>0.553990</td>\n",
       "      <td>0.601144</td>\n",
       "      <td>0.579828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.995700</td>\n",
       "      <td>0.933204</td>\n",
       "      <td>0.626339</td>\n",
       "      <td>0.620028</td>\n",
       "      <td>0.626286</td>\n",
       "      <td>0.626339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.922800</td>\n",
       "      <td>0.890986</td>\n",
       "      <td>0.637053</td>\n",
       "      <td>0.631321</td>\n",
       "      <td>0.658179</td>\n",
       "      <td>0.637053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.874400</td>\n",
       "      <td>0.874373</td>\n",
       "      <td>0.652077</td>\n",
       "      <td>0.635931</td>\n",
       "      <td>0.666202</td>\n",
       "      <td>0.652077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='180' max='957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [180/957 00:05 < 00:23, 33.33 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "print(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "7-xpP2jK1qTN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mroberta-ukrainian-sentiment\u001b[0m at: \u001b[34mhttps://wandb.ai/shynkarov-pn-ukrainian-catholic-university/ukrainian-sentiment/runs/vl9tnzbt\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250420_080024-vl9tnzbt/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fp8RRIa5sg6q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Hyper params tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 0.01, 0.1)\n",
    "    \n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results_optuna\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=2,\n",
    "        save_total_limit=10,\n",
    "        # warmup_ratio=0.1,\n",
    "        num_train_epochs=5,\n",
    "        weight_decay=weight_decay,\n",
    "        logging_dir=\"./logs_optuna\",\n",
    "        logging_steps=50,\n",
    "        eval_steps=50,\n",
    "        save_steps=50,\n",
    "        eval_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        report_to=\"wandb\",\n",
    "        run_name=\"optuna\",\n",
    "        metric_for_best_model=\"f1\",\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer and train model\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=6)]\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model and return validation accuracy\n",
    "    eval_results = trainer.evaluate()\n",
    "    return eval_results[\"eval_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 23:10:59,094] A new study created in memory with name: no-name-8513712f-27d0-42a3-b86a-4666b4e6c40c\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1050' max='1450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1050/1450 07:25 < 02:49, 2.35 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.917200</td>\n",
       "      <td>0.742903</td>\n",
       "      <td>0.677864</td>\n",
       "      <td>0.674121</td>\n",
       "      <td>0.693244</td>\n",
       "      <td>0.677864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.724700</td>\n",
       "      <td>0.679379</td>\n",
       "      <td>0.707149</td>\n",
       "      <td>0.706546</td>\n",
       "      <td>0.708010</td>\n",
       "      <td>0.707149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.682300</td>\n",
       "      <td>0.679730</td>\n",
       "      <td>0.708010</td>\n",
       "      <td>0.704029</td>\n",
       "      <td>0.725822</td>\n",
       "      <td>0.708010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.697400</td>\n",
       "      <td>0.661064</td>\n",
       "      <td>0.721792</td>\n",
       "      <td>0.718715</td>\n",
       "      <td>0.726476</td>\n",
       "      <td>0.721792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.666200</td>\n",
       "      <td>0.645199</td>\n",
       "      <td>0.732989</td>\n",
       "      <td>0.730710</td>\n",
       "      <td>0.742404</td>\n",
       "      <td>0.732989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.639100</td>\n",
       "      <td>0.663719</td>\n",
       "      <td>0.717485</td>\n",
       "      <td>0.716716</td>\n",
       "      <td>0.723710</td>\n",
       "      <td>0.717485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.569200</td>\n",
       "      <td>0.678832</td>\n",
       "      <td>0.722653</td>\n",
       "      <td>0.723358</td>\n",
       "      <td>0.726377</td>\n",
       "      <td>0.722653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.538900</td>\n",
       "      <td>0.670532</td>\n",
       "      <td>0.721792</td>\n",
       "      <td>0.719441</td>\n",
       "      <td>0.729942</td>\n",
       "      <td>0.721792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.582400</td>\n",
       "      <td>0.656048</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.722225</td>\n",
       "      <td>0.720930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>0.663014</td>\n",
       "      <td>0.736434</td>\n",
       "      <td>0.734845</td>\n",
       "      <td>0.742807</td>\n",
       "      <td>0.736434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.562900</td>\n",
       "      <td>0.652534</td>\n",
       "      <td>0.726960</td>\n",
       "      <td>0.726010</td>\n",
       "      <td>0.731966</td>\n",
       "      <td>0.726960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.530200</td>\n",
       "      <td>0.657117</td>\n",
       "      <td>0.735573</td>\n",
       "      <td>0.733983</td>\n",
       "      <td>0.742231</td>\n",
       "      <td>0.735573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.476500</td>\n",
       "      <td>0.677330</td>\n",
       "      <td>0.731266</td>\n",
       "      <td>0.729915</td>\n",
       "      <td>0.732986</td>\n",
       "      <td>0.731266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.433600</td>\n",
       "      <td>0.685782</td>\n",
       "      <td>0.741602</td>\n",
       "      <td>0.739655</td>\n",
       "      <td>0.744078</td>\n",
       "      <td>0.741602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.454400</td>\n",
       "      <td>0.667982</td>\n",
       "      <td>0.751938</td>\n",
       "      <td>0.751338</td>\n",
       "      <td>0.751899</td>\n",
       "      <td>0.751938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.452900</td>\n",
       "      <td>0.669289</td>\n",
       "      <td>0.739018</td>\n",
       "      <td>0.737966</td>\n",
       "      <td>0.740556</td>\n",
       "      <td>0.739018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.488900</td>\n",
       "      <td>0.668482</td>\n",
       "      <td>0.736434</td>\n",
       "      <td>0.736279</td>\n",
       "      <td>0.736792</td>\n",
       "      <td>0.736434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.387000</td>\n",
       "      <td>0.700487</td>\n",
       "      <td>0.738157</td>\n",
       "      <td>0.737830</td>\n",
       "      <td>0.739906</td>\n",
       "      <td>0.738157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.350400</td>\n",
       "      <td>0.718177</td>\n",
       "      <td>0.743325</td>\n",
       "      <td>0.742481</td>\n",
       "      <td>0.746658</td>\n",
       "      <td>0.743325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.360700</td>\n",
       "      <td>0.724493</td>\n",
       "      <td>0.739018</td>\n",
       "      <td>0.738628</td>\n",
       "      <td>0.739209</td>\n",
       "      <td>0.739018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.372400</td>\n",
       "      <td>0.725968</td>\n",
       "      <td>0.745047</td>\n",
       "      <td>0.744353</td>\n",
       "      <td>0.747551</td>\n",
       "      <td>0.745047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [146/146 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 23:18:29,295] Trial 0 finished with value: 0.7450473729543498 and parameters: {'learning_rate': 1.1735182865186952e-05, 'batch_size': 16, 'weight_decay': 0.012916490115700903}. Best is trial 0 with value: 0.7450473729543498.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='252' max='1450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 252/1450 01:45 < 08:26, 2.36 it/s, Epoch 0.86/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.454600</td>\n",
       "      <td>0.820859</td>\n",
       "      <td>0.712317</td>\n",
       "      <td>0.710457</td>\n",
       "      <td>0.728403</td>\n",
       "      <td>0.712317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.390800</td>\n",
       "      <td>0.819037</td>\n",
       "      <td>0.727821</td>\n",
       "      <td>0.727423</td>\n",
       "      <td>0.732244</td>\n",
       "      <td>0.727821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.339600</td>\n",
       "      <td>0.795487</td>\n",
       "      <td>0.716624</td>\n",
       "      <td>0.714898</td>\n",
       "      <td>0.728954</td>\n",
       "      <td>0.716624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.389900</td>\n",
       "      <td>0.819856</td>\n",
       "      <td>0.712317</td>\n",
       "      <td>0.713834</td>\n",
       "      <td>0.720759</td>\n",
       "      <td>0.712317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.374800</td>\n",
       "      <td>0.763311</td>\n",
       "      <td>0.729543</td>\n",
       "      <td>0.729156</td>\n",
       "      <td>0.729498</td>\n",
       "      <td>0.729543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and run the Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 1.1735182865186952e-05, 'batch_size': 16, 'weight_decay': 0.012916490115700903}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters: {'learning_rate': 1.1735182865186952e-05, 'batch_size': 16, 'weight_decay': 0.012916490115700903}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1.1735182865186952e-05,\n",
       " 'batch_size': 16,\n",
       " 'weight_decay': 0.012916490115700903}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "predictions = trainer.predict(test_dataset)\n",
    "preds = np.argmax(predictions.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = label_encoder.transform(test_df['annotator_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mixed', 'negative', 'neutral', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.05      0.09        60\n",
      "           1       0.71      0.75      0.73       455\n",
      "           2       0.65      0.67      0.66       471\n",
      "           3       0.65      0.68      0.66       237\n",
      "\n",
      "    accuracy                           0.67      1223\n",
      "   macro avg       0.65      0.54      0.53      1223\n",
      "weighted avg       0.67      0.67      0.66      1223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "print(classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.32      0.32        60\n",
      "           1       0.76      0.70      0.73       455\n",
      "           2       0.64      0.75      0.69       471\n",
      "           3       0.72      0.59      0.65       237\n",
      "\n",
      "    accuracy                           0.68      1223\n",
      "   macro avg       0.61      0.59      0.59      1223\n",
      "weighted avg       0.68      0.68      0.68      1223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report -- second try\n",
    "print(classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.03      0.06        60\n",
      "           1       0.74      0.76      0.75       455\n",
      "           2       0.66      0.79      0.72       471\n",
      "           3       0.76      0.61      0.68       237\n",
      "\n",
      "    accuracy                           0.71      1223\n",
      "   macro avg       0.62      0.55      0.55      1223\n",
      "weighted avg       0.69      0.71      0.69      1223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report -- third try\n",
    "print(classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.02      0.03        60\n",
      "           1       0.72      0.75      0.74       455\n",
      "           2       0.68      0.77      0.72       471\n",
      "           3       0.71      0.64      0.67       237\n",
      "\n",
      "    accuracy                           0.70      1223\n",
      "   macro avg       0.56      0.54      0.54      1223\n",
      "weighted avg       0.68      0.70      0.68      1223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report -- fourth try\n",
    "print(classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.84      0.77       455\n",
      "           1       0.72      0.69      0.70       471\n",
      "           2       0.79      0.63      0.70       237\n",
      "\n",
      "    accuracy                           0.73      1163\n",
      "   macro avg       0.74      0.72      0.73      1163\n",
      "weighted avg       0.74      0.73      0.73      1163\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report -- fifth try\n",
    "print(classification_report(test_labels, preds))\n",
    "# trainer.save_model('best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report -- sixth try, mixed class with cross entropy\n",
    "print(classification_report(test_labels, preds))\n",
    "# trainer.save_model('best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.20      0.28        60\n",
      "           1       0.71      0.77      0.74       455\n",
      "           2       0.69      0.73      0.71       471\n",
      "           3       0.77      0.67      0.72       237\n",
      "\n",
      "    accuracy                           0.71      1223\n",
      "   macro avg       0.66      0.59      0.61      1223\n",
      "weighted avg       0.70      0.71      0.70      1223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report -- seventh try, mixed class with cross entropy\n",
    "print(classification_report(test_labels, preds))\n",
    "# trainer.save_model('best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.20      0.26        60\n",
      "           1       0.73      0.70      0.71       455\n",
      "           2       0.64      0.77      0.70       471\n",
      "           3       0.70      0.55      0.62       237\n",
      "\n",
      "    accuracy                           0.67      1223\n",
      "   macro avg       0.61      0.56      0.57      1223\n",
      "weighted avg       0.67      0.67      0.67      1223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report -- mBERT\n",
    "print(classification_report(test_labels, preds))\n",
    "# trainer.save_model('best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
